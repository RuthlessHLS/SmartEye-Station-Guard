<!-- AIåˆ†æå™¨ç»„ä»¶ -->
<template>
  <div class="ai-analyzer">
    <canvas ref="overlayCanvas" class="overlay-canvas"></canvas>
  </div>
</template>

<script setup>
import { ref, onMounted, onUnmounted, watch, nextTick } from 'vue'
import { useAIAnalysis } from '@/composables/useAIAnalysis'

const props = defineProps({
  video: {
    type: [Object, null],
    required: false,
    default: null
  },
  cameraId: {
    type: String,
    required: true
  },
  enabled: {
    type: Boolean,
    default: false
  },
  realtimeMode: {
    type: Boolean,
    default: true
  },
  dangerZones: {
    type: Array,
    default: () => []
  },
  currentZonePoints: {
    type: Array,
    default: () => []
  },
  detectionResults: {
    type: Array,
    default: () => []
  }
})

const emit = defineEmits(['detection-results', 'performance-stats', 'canvas-click'])

const overlayCanvas = ref(null)
const canvasContext = ref(null)
let isProcessingFrame = false
let analysisTimer = null

const {
  sendFrameToAI,
  processResults,
  updateStats,
  getStats
} = useAIAnalysis(props.cameraId)

// å¤„ç†å•ä¸ªå¸§
const handleFrame = (blob, width, height) => {
  if (!blob) {
    isProcessingFrame = false
    return
  }
  
  sendFrameToAI(blob, width, height)
    .then(results => {
      if (results) {
        const processed = processResults(results)
        emit('detection-results', processed)
      }
    })
    .catch(error => console.error('AIåˆ†æå¤±è´¥:', error))
    .finally(() => {
      isProcessingFrame = false
      updateStats()
      emit('performance-stats', getStats())
    })
}

// æ•è·è§†é¢‘å¸§
const captureFrame = () => {
  if (!props.video || isProcessingFrame || !props.enabled) {
    return
  }

  isProcessingFrame = true

  try {
    const canvas = document.createElement('canvas')
    const ctx = canvas.getContext('2d')
    
    // è·å–è§†é¢‘çš„å®é™…å°ºå¯¸
    const videoWidth = props.video.videoWidth || props.video.width || 640
    const videoHeight = props.video.videoHeight || props.video.height || 480
    
    if (videoWidth === 0 || videoHeight === 0) {
      console.warn('è§†é¢‘å°ºå¯¸æ— æ•ˆï¼Œè·³è¿‡å¸§æ•è·')
      isProcessingFrame = false
      return
    }
    
    canvas.width = videoWidth
    canvas.height = videoHeight
    
    // ä½¿ç”¨ä¸´æ—¶canvasçš„contextæ¥ç»˜åˆ¶è§†é¢‘å¸§
    ctx.drawImage(props.video, 0, 0, videoWidth, videoHeight)
    canvas.toBlob(blob => handleFrame(blob, videoWidth, videoHeight), 'image/jpeg', 0.8)
  } catch (error) {
    console.error('å¸§æ•è·å¤±è´¥:', error)
    isProcessingFrame = false
  }
}

// å¯åŠ¨åˆ†æå¾ªç¯
const startAnalysis = () => {
  if (!analysisTimer) {
    analysisTimer = setInterval(captureFrame, props.realtimeMode ? 100 : 500)
  }
}

// åœæ­¢åˆ†æ
const stopAnalysis = () => {
  if (analysisTimer) {
    clearInterval(analysisTimer)
    analysisTimer = null
  }
}

// ç›‘å¬å¯ç”¨çŠ¶æ€å˜åŒ–
watch(() => props.enabled, (newVal) => {
  if (newVal) {
    startAnalysis()
  } else {
    stopAnalysis()
  }
})

// ç»˜åˆ¶æ£€æµ‹ç»“æœ
const drawDetectionResults = (results) => {
  if (!canvasContext.value || !overlayCanvas.value) return
  
  // æ¸…é™¤ç”»å¸ƒ
  canvasContext.value.clearRect(0, 0, overlayCanvas.value.width, overlayCanvas.value.height)
  
  if (!results || results.length === 0) {
    console.log('ğŸ¨ æ²¡æœ‰æ£€æµ‹ç»“æœéœ€è¦ç»˜åˆ¶')
    return
  }
  
  canvasContext.value.save()
  
  // è·å–Canvaså°ºå¯¸
  const canvasWidth = overlayCanvas.value.width
  const canvasHeight = overlayCanvas.value.height
  
  console.log(`ğŸ¨ Canvaså°ºå¯¸: ${canvasWidth}x${canvasHeight}ï¼Œç»˜åˆ¶ ${results.length} ä¸ªæ£€æµ‹æ¡†`)
  
  // ç®€åŒ–çš„åæ ‡è½¬æ¢é€»è¾‘
  let scaleX = 1, scaleY = 1
  
  if (props.video && props.video.videoWidth && props.video.videoHeight) {
    // ç›´æ¥ä½¿ç”¨è§†é¢‘åŸå§‹å°ºå¯¸åˆ°Canvaså°ºå¯¸çš„æ¯”ä¾‹
    scaleX = canvasWidth / props.video.videoWidth
    scaleY = canvasHeight / props.video.videoHeight
    
    console.log('ğŸ“ åæ ‡è½¬æ¢å‚æ•°:', {
      videoSize: `${props.video.videoWidth}x${props.video.videoHeight}`,
      canvasSize: `${canvasWidth}x${canvasHeight}`,
      scale: `${scaleX.toFixed(3)}x${scaleY.toFixed(3)}`
    })
  } else {
    console.warn('âš ï¸ æ— æ³•è·å–è§†é¢‘å°ºå¯¸ï¼Œä½¿ç”¨é»˜è®¤ç¼©æ”¾æ¯”ä¾‹')
  }
  
  results.forEach((result, index) => {
    // é€‚é…ä¸åŒçš„æ•°æ®æ ¼å¼
    let x, y, width, height, confidence, label
    
    if (result.bbox && Array.isArray(result.bbox)) {
      // AIVideoMonitoræ ¼å¼: {bbox: [x1, y1, x2, y2], confidence, label}
      const [x1, y1, x2, y2] = result.bbox
      
      // åº”ç”¨åæ ‡è½¬æ¢
      x = Math.max(0, Math.min(x1 * scaleX, canvasWidth))
      y = Math.max(0, Math.min(y1 * scaleY, canvasHeight))
      width = Math.max(0, Math.min((x2 - x1) * scaleX, canvasWidth - x))
      height = Math.max(0, Math.min((y2 - y1) * scaleY, canvasHeight - y))
      
      confidence = result.confidence || 0
      label = result.label || result.class_name || 'æœªçŸ¥'
    } else {
      // å…¶ä»–æ ¼å¼: {x, y, width, height, confidence, class_name}
      x = Math.max(0, Math.min((result.x || 0) * scaleX, canvasWidth))
      y = Math.max(0, Math.min((result.y || 0) * scaleY, canvasHeight))
      width = Math.max(0, Math.min((result.width || 0) * scaleX, canvasWidth - x))
      height = Math.max(0, Math.min((result.height || 0) * scaleY, canvasHeight - y))
      confidence = result.confidence || 0
      label = result.class_name || result.label || 'æœªçŸ¥'
    }
    
    // è·³è¿‡æ— æ•ˆçš„æ£€æµ‹æ¡†
    if (width <= 0 || height <= 0) {
      console.warn(`âš ï¸ è·³è¿‡æ— æ•ˆæ£€æµ‹æ¡† ${index}:`, { x, y, width, height })
      return
    }
    
    console.log(`ğŸ¯ ç»˜åˆ¶æ£€æµ‹æ¡† ${index}:`, { 
      type: result.type, 
      label, 
      confidence: (confidence * 100).toFixed(1) + '%',
      originalBbox: [...result.bbox], // å±•å¼€æ•°ç»„ä»¥æ˜¾ç¤ºå®é™…å€¼
      bboxFormat: 'left,top,right,bottom',
      videoSize: props.video ? `${props.video.videoWidth}x${props.video.videoHeight}` : 'unknown',
      canvasSize: `${canvasWidth}x${canvasHeight}`,
      scaleFactors: `${scaleX.toFixed(3)}x${scaleY.toFixed(3)}`,
      transformedCoords: {
        x: x.toFixed(1), 
        y: y.toFixed(1), 
        width: width.toFixed(1), 
        height: height.toFixed(1),
        right: (x + width).toFixed(1),
        bottom: (y + height).toFixed(1)
      },
      calculationSteps: {
        step1_originalCoords: `left=${result.bbox[0]}, top=${result.bbox[1]}, right=${result.bbox[2]}, bottom=${result.bbox[3]}`,
        step2_afterScale: `x=${(result.bbox[0] * scaleX).toFixed(1)}, y=${(result.bbox[1] * scaleY).toFixed(1)}, w=${((result.bbox[2] - result.bbox[0]) * scaleX).toFixed(1)}, h=${((result.bbox[3] - result.bbox[1]) * scaleY).toFixed(1)}`,
        step3_clampedFinal: `x=${x.toFixed(1)}, y=${y.toFixed(1)}, w=${width.toFixed(1)}, h=${height.toFixed(1)}`
      }
    })
    
    // æ ¹æ®æ£€æµ‹ç±»å‹é€‰æ‹©é¢œè‰²
    let color = '#00ff00' // é»˜è®¤ç»¿è‰²
    if (result.type === 'face') {
      color = '#409EFF' // è“è‰²
    } else if (result.type === 'unknown_face') {
      color = '#F56C6C' // çº¢è‰²
    } else if (result.type === 'fire_detection' || result.type === 'fire') {
      color = '#FF4444' // æ·±çº¢è‰²
    } else if (result.type === 'person') {
      color = '#67C23A' // ç»¿è‰²
    }
    
    // ç»˜åˆ¶è¾¹ç•Œæ¡†
    canvasContext.value.strokeStyle = color
    canvasContext.value.lineWidth = 3
    canvasContext.value.strokeRect(x, y, width, height)
    
    // ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
    const labelText = `${label} ${(confidence * 100).toFixed(1)}%`
    canvasContext.value.font = 'bold 14px Arial'
    const textMetrics = canvasContext.value.measureText(labelText)
    const textHeight = 22
    const padding = 6
    
    // ç¡®ä¿æ ‡ç­¾ä¸ä¼šè¶…å‡ºCanvasè¾¹ç•Œ
    const labelY = Math.max(textHeight, y)
    const labelX = Math.min(x, canvasWidth - textMetrics.width - padding * 2)
    
    canvasContext.value.fillStyle = color
    canvasContext.value.fillRect(labelX, labelY - textHeight, textMetrics.width + padding * 2, textHeight)
    
    // ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
    canvasContext.value.fillStyle = '#ffffff'
    canvasContext.value.fillText(labelText, labelX + padding, labelY - 6)
  })
  
  canvasContext.value.restore()
  
  console.log(`âœ… æˆåŠŸç»˜åˆ¶ ${results.length} ä¸ªæ£€æµ‹æ¡†`)
}

// ç»˜åˆ¶å±é™©åŒºåŸŸ
const drawDangerZones = () => {
  if (!canvasContext.value || !overlayCanvas.value) return
  
  // å…ˆç»˜åˆ¶æ£€æµ‹ç»“æœï¼ˆä¼šæ¸…é™¤ç”»å¸ƒï¼‰
  if (props.detectionResults && props.detectionResults.length > 0) {
    drawDetectionResults(props.detectionResults)
  } else {
    // å¦‚æœæ²¡æœ‰æ£€æµ‹ç»“æœï¼Œæ¸…é™¤ç”»å¸ƒ
    canvasContext.value.clearRect(0, 0, overlayCanvas.value.width, overlayCanvas.value.height)
  }
  
  // åœ¨æ£€æµ‹ç»“æœä¹‹ä¸Šç»˜åˆ¶å·²ä¿å­˜çš„å±é™©åŒºåŸŸ
  props.dangerZones.forEach(zone => {
    drawZone(zone.coordinates, '#f56c6c', zone.name, true)
  })
  
  // ç»˜åˆ¶æ­£åœ¨ç»˜åˆ¶çš„åŒºåŸŸ
  if (props.currentZonePoints.length > 0) {
    drawZone(props.currentZonePoints, '#409EFF', 'æ–°åŒºåŸŸ', false)
  }
}

// ç»˜åˆ¶å•ä¸ªåŒºåŸŸ
const drawZone = (points, color, name, isComplete) => {
  if (!canvasContext.value || points.length === 0) return

  canvasContext.value.save()

  // ç»˜åˆ¶åŒºåŸŸè¾¹ç•Œ
  canvasContext.value.strokeStyle = color
  canvasContext.value.lineWidth = 3
  canvasContext.value.setLineDash(isComplete ? [] : [8, 4])

  canvasContext.value.beginPath()
  canvasContext.value.moveTo(points[0][0], points[0][1])

  for (let i = 1; i < points.length; i++) {
    canvasContext.value.lineTo(points[i][0], points[i][1])
  }

  if (isComplete && points.length > 2) {
    canvasContext.value.closePath()

    // å¡«å……åŠé€æ˜èƒŒæ™¯
    canvasContext.value.fillStyle = color + '20' // æ·»åŠ é€æ˜åº¦
    canvasContext.value.fill()
  }

  canvasContext.value.stroke()

  // ç»˜åˆ¶é¡¶ç‚¹
  points.forEach((point, index) => {
    canvasContext.value.fillStyle = color
    canvasContext.value.beginPath()
    canvasContext.value.arc(point[0], point[1], 4, 0, 2 * Math.PI)
    canvasContext.value.fill()

    // æ˜¾ç¤ºé¡¶ç‚¹åºå·
    canvasContext.value.fillStyle = '#ffffff'
    canvasContext.value.font = '12px Arial'
    canvasContext.value.textAlign = 'center'
    canvasContext.value.fillText(index + 1, point[0], point[1] + 4)
  })

  // ç»˜åˆ¶åŒºåŸŸåç§°
  if (points.length > 0) {
    const centerX = points.reduce((sum, point) => sum + point[0], 0) / points.length
    const centerY = points.reduce((sum, point) => sum + point[1], 0) / points.length

    canvasContext.value.fillStyle = color
    canvasContext.value.font = 'bold 14px Arial'
    canvasContext.value.textAlign = 'center'
    canvasContext.value.fillText(name, centerX, centerY)
  }

  canvasContext.value.restore()
}

// å¤„ç†Canvasç‚¹å‡»äº‹ä»¶
const handleCanvasClick = (event) => {
  const rect = overlayCanvas.value.getBoundingClientRect()
  const x = event.clientX - rect.left
  const y = event.clientY - rect.top

  // è½¬æ¢ä¸ºç›¸å¯¹äºCanvasçš„åæ ‡
  const canvasX = (x / rect.width) * overlayCanvas.value.width
  const canvasY = (y / rect.height) * overlayCanvas.value.height

  emit('canvas-click', { x: canvasX, y: canvasY, originalEvent: event })
}

// å¯ç”¨/ç¦ç”¨Canvasäº¤äº’
const setCanvasInteractive = (interactive) => {
  if (overlayCanvas.value) {
    overlayCanvas.value.style.pointerEvents = interactive ? 'auto' : 'none'
    if (interactive) {
      overlayCanvas.value.addEventListener('click', handleCanvasClick)
    } else {
      overlayCanvas.value.removeEventListener('click', handleCanvasClick)
    }
  }
}

// è°ƒæ•´Canvaså°ºå¯¸
const resizeCanvas = () => {
  if (!overlayCanvas.value) {
    console.warn('Canvaså…ƒç´ ä¸å­˜åœ¨ï¼Œè·³è¿‡å°ºå¯¸è°ƒæ•´')
    return
  }
  
  try {
    let containerRect = null
    
    // ä¼˜å…ˆä½¿ç”¨videoå…ƒç´ çš„å°ºå¯¸
    if (props.video && props.video.getBoundingClientRect) {
      containerRect = props.video.getBoundingClientRect()
      console.log('ğŸ“ ä½¿ç”¨videoå…ƒç´ å°ºå¯¸:', containerRect)
    }
    
    // å¦‚æœvideoå…ƒç´ æ— æ•ˆï¼Œä½¿ç”¨çˆ¶å®¹å™¨å°ºå¯¸
    if (!containerRect || containerRect.width <= 0 || containerRect.height <= 0) {
      const parent = overlayCanvas.value.parentElement
      if (parent) {
        containerRect = parent.getBoundingClientRect()
        console.log('ğŸ“ ä½¿ç”¨çˆ¶å®¹å™¨å°ºå¯¸:', containerRect)
      }
    }
    
    // æœ€åçš„åå¤‡æ–¹æ¡ˆï¼šä½¿ç”¨å›ºå®šå°ºå¯¸
    if (!containerRect || containerRect.width <= 0 || containerRect.height <= 0) {
      containerRect = { width: 640, height: 480 }
      console.log('ğŸ“ ä½¿ç”¨é»˜è®¤å°ºå¯¸:', containerRect)
    }
    
    // åº”ç”¨å°ºå¯¸è®¾ç½®
    const width = Math.floor(containerRect.width)
    const height = Math.floor(containerRect.height)
    
    if (width > 0 && height > 0) {
      // è®¾ç½®Canvasçš„æ˜¾ç¤ºå°ºå¯¸
      overlayCanvas.value.style.width = width + 'px'
      overlayCanvas.value.style.height = height + 'px'
      
      // è®¾ç½®Canvasçš„å†…éƒ¨åˆ†è¾¨ç‡ï¼ˆç”¨äºç»˜åˆ¶ï¼‰
      overlayCanvas.value.width = width
      overlayCanvas.value.height = height
      
      console.log('âœ… Canvaså°ºå¯¸å·²è°ƒæ•´:', width, 'x', height)
      
      // é‡æ–°ç»˜åˆ¶å†…å®¹
      nextTick(() => {
        drawDangerZones()
      })
    } else {
      console.warn('âš ï¸ æ— æ•ˆçš„å®¹å™¨å°ºå¯¸:', { width, height })
    }
  } catch (error) {
    console.error('âŒ è°ƒæ•´Canvaså°ºå¯¸å¤±è´¥:', error)
  }
}

// ç›‘å¬å±æ€§å˜åŒ–ï¼Œé‡æ–°ç»˜åˆ¶
watch(() => [props.dangerZones, props.currentZonePoints, props.detectionResults], ([newDangerZones, newCurrentZonePoints, newDetectionResults]) => {
  console.log('ğŸ”„ AIAnalyzer propså˜åŒ–:', {
    dangerZones: newDangerZones?.length || 0,
    currentZonePoints: newCurrentZonePoints?.length || 0,
    detectionResults: newDetectionResults?.length || 0
  })
  drawDangerZones()
}, { deep: true, immediate: true })

// ç›‘å¬videoå±æ€§å˜åŒ–ï¼Œé‡æ–°åˆå§‹åŒ–Canvas
watch(() => props.video, (newVideo, oldVideo) => {
  console.log('ğŸ”„ videoå±æ€§å˜åŒ–:', { 
    old: oldVideo ? 'exists' : 'null', 
    new: newVideo ? 'exists' : 'null' 
  })
  
  if (newVideo) {
    // ç«‹å³è°ƒæ•´Canvaså°ºå¯¸
    nextTick(() => {
      resizeCanvas()
    })
    
    // å»¶è¿Ÿå†æ¬¡è°ƒæ•´ï¼Œç¡®ä¿videoå…ƒç´ å®Œå…¨åŠ è½½
    setTimeout(() => {
      resizeCanvas()
    }, 200)
  }
}, { immediate: true })



// æš´éœ²æ–¹æ³•ç»™çˆ¶ç»„ä»¶
defineExpose({
  drawDangerZones,
  setCanvasInteractive,
  resizeCanvas,
  getCanvas: () => overlayCanvas.value,
  getContext: () => canvasContext.value
})

// ç»„ä»¶æŒ‚è½½æ—¶åˆå§‹åŒ–
onMounted(() => {
  console.log('ğŸ”§ AIAnalyzerç»„ä»¶æŒ‚è½½')
  
  if (overlayCanvas.value) {
    canvasContext.value = overlayCanvas.value.getContext('2d')
    console.log('âœ… Canvasä¸Šä¸‹æ–‡å·²åˆ›å»º')
    
    // ç«‹å³å°è¯•è°ƒæ•´Canvaså°ºå¯¸
    resizeCanvas()
    
    // å¤šæ¬¡å°è¯•è°ƒæ•´Canvaså°ºå¯¸ï¼Œç¡®ä¿videoå…ƒç´ å®Œå…¨åŠ è½½
    const resizeAttempts = [100, 300, 500, 1000]
    resizeAttempts.forEach(delay => {
      setTimeout(() => {
        resizeCanvas()
      }, delay)
    })
    
    // ç›‘å¬çª—å£å¤§å°å˜åŒ–
    window.addEventListener('resize', resizeCanvas)
  }
  
  // å»¶è¿Ÿå¯åŠ¨åˆ†æï¼Œç¡®ä¿videoå…ƒç´ å·²ç»å‡†å¤‡å¥½
  if (props.enabled) {
    setTimeout(() => {
      startAnalysis()
    }, 200)
  }
})

// ç»„ä»¶å¸è½½æ—¶æ¸…ç†
onUnmounted(() => {
  stopAnalysis()
  
  // æ¸…ç†äº‹ä»¶ç›‘å¬å™¨
  if (overlayCanvas.value) {
    overlayCanvas.value.removeEventListener('click', handleCanvasClick)
  }
  window.removeEventListener('resize', resizeCanvas)
})
</script>

<style scoped>
.ai-analyzer {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  z-index: 10;
  pointer-events: none;
}

.overlay-canvas {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  pointer-events: none;
  z-index: 10;
}
</style> 