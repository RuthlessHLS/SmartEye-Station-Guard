<template>
  <div class="ai-video-monitor">
    <el-container>
      <!-- é¡¶éƒ¨æ§åˆ¶æ  -->
      <el-header height="80px">
        <div class="header-content">
          <h2>ğŸ¤– AIæ™ºèƒ½è§†é¢‘ç›‘æ§</h2>
          <div class="header-controls">
            <el-button-group>
              <el-button 
                type="primary" 
                :disabled="isStreaming"
                @click="startLocalCamera"
              >
                <el-icon><VideoCamera /></el-icon>
                å¯åŠ¨æ‘„åƒå¤´
              </el-button>
              <el-button 
                type="danger" 
                :disabled="!isStreaming"
                @click="stopCamera"
              >
                <el-icon><Close /></el-icon>
                åœæ­¢ç›‘æ§
              </el-button>
              <el-button 
                :type="aiAnalysisEnabled ? 'success' : 'info'"
                :disabled="!isStreaming"
                @click="toggleAIAnalysis"
              >
                <el-icon><Cpu /></el-icon>
                {{ aiAnalysisEnabled ? 'AIåˆ†æä¸­' : 'å¼€å¯AIåˆ†æ' }}
              </el-button>
            </el-button-group>
          </div>
        </div>
      </el-header>

      <el-main>
        <el-row :gutter="20">
          <!-- å·¦ä¾§è§†é¢‘æ˜¾ç¤ºåŒº -->
          <el-col :span="16">
            <el-card class="video-card" shadow="always">
              <template #header>
                <div class="card-header">
                  <span>ğŸ“¹ å®æ—¶è§†é¢‘ç›‘æ§</span>
                  <el-tag 
                    :type="isStreaming ? 'success' : 'danger'"
                    size="small"
                  >
                    {{ isStreaming ? 'ç›‘æ§ä¸­' : 'æœªå¯åŠ¨' }}
                  </el-tag>
                </div>
              </template>
              
              <div class="video-container" ref="videoContainer">
                <video 
                  ref="videoElement"
                  class="video-player"
                  autoplay
                  muted
                  playsinline
                  @loadedmetadata="onVideoLoaded"
                ></video>
                
                <!-- AIæ£€æµ‹ç»“æœè¦†ç›–å±‚ -->
                <canvas 
                  ref="overlayCanvas"
                  class="overlay-canvas"
                ></canvas>
                
                <!-- æ‘„åƒå¤´é€‰æ‹©å¯¹è¯æ¡† -->
                <div v-if="!isStreaming" class="camera-placeholder">
                  <el-icon class="placeholder-icon"><VideoCamera /></el-icon>
                  <p>ç‚¹å‡»"å¯åŠ¨æ‘„åƒå¤´"å¼€å§‹æ™ºèƒ½ç›‘æ§</p>
                  <el-select 
                    v-model="selectedDeviceId" 
                    placeholder="é€‰æ‹©æ‘„åƒå¤´è®¾å¤‡"
                    class="device-select"
                  >
                    <el-option
                      v-for="device in videoDevices"
                      :key="device.deviceId"
                      :label="device.label || `æ‘„åƒå¤´ ${device.deviceId.slice(0, 8)}`"
                      :value="device.deviceId"
                    />
                  </el-select>
                </div>
              </div>
            </el-card>
          </el-col>

          <!-- å³ä¾§æ§åˆ¶å’Œä¿¡æ¯é¢æ¿ -->
          <el-col :span="8">
            <!-- AIåˆ†æè®¾ç½® -->
            <el-card class="control-panel" shadow="never">
              <template #header>
                <span>ğŸ¯ AIåˆ†æè®¾ç½®</span>
              </template>
              
              <div class="analysis-settings">
                <el-form label-width="100px">
                  <el-form-item label="äººè„¸è¯†åˆ«">
                    <el-switch 
                      v-model="aiSettings.faceRecognition"
                      :disabled="!isStreaming"
                      @change="updateAISettings"
                    />
                  </el-form-item>
                  <el-form-item label="ç›®æ ‡æ£€æµ‹">
                    <el-switch 
                      v-model="aiSettings.objectDetection"
                      :disabled="!isStreaming"
                      @change="updateAISettings"
                    />
                  </el-form-item>
                  <el-form-item label="è¡Œä¸ºåˆ†æ">
                    <el-switch 
                      v-model="aiSettings.behaviorAnalysis"
                      :disabled="!isStreaming"
                      @change="updateAISettings"
                    />
                  </el-form-item>
                  <el-form-item label="å£°éŸ³æ£€æµ‹">
                    <el-switch 
                      v-model="aiSettings.soundDetection"
                      :disabled="!isStreaming"
                      @change="updateAISettings"
                    />
                  </el-form-item>
                  <el-form-item label="å®æ—¶æ¨¡å¼">
                    <el-switch 
                      v-model="aiSettings.realtimeMode"
                      :disabled="!isStreaming"
                      active-text="é«˜é¢‘æ£€æµ‹"
                      inactive-text="èŠ‚èƒ½æ¨¡å¼"
                      @change="updateAISettings"
                    />
                    <div class="frequency-hint">
                      <small v-if="aiSettings.realtimeMode" style="color: #409EFF;">
                        ğŸš€ å®æ—¶æ¨¡å¼ï¼š~15FPSé«˜é¢‘æ£€æµ‹ï¼Œå“åº”æ›´å¿«
                      </small>
                      <small v-else style="color: #67C23A;">
                        ğŸ’¡ èŠ‚èƒ½æ¨¡å¼ï¼šæ™ºèƒ½è°ƒé¢‘ï¼Œçœç”µä¼˜åŒ–
                      </small>
                    </div>
                  </el-form-item>
                  <el-form-item label="æ£€æµ‹é¢‘ç‡">
                    <el-slider
                      v-model="analysisInterval"
                      :min="100"
                      :max="2000"
                      :step="100"
                      :disabled="!isStreaming"
                      show-input
                      input-size="small"
                      @change="updateAnalysisInterval"
                    />
                    <div class="frequency-hint">
                      <small>{{Math.round(1000/analysisInterval)}} FPS (æ¨è: 100-500ms)</small>
                    </div>
                  </el-form-item>
                  
                  <el-form-item label="æ€§èƒ½ä¼˜åŒ–" v-if="isStreaming">
                    <div class="optimization-status">
                      <div class="opt-item">
                        <el-icon><Cpu /></el-icon>
                        <span>å¸§å·®æ£€æµ‹: å·²å¯ç”¨</span>
                      </div>
                      <div class="opt-item">
                        <el-icon><VideoCamera /></el-icon>
                        <span>åŠ¨æ€ç”»è´¨: è‡ªé€‚åº”</span>
                      </div>
                      <div class="opt-item">
                        <el-text type="success" size="small">
                          å½“å‰å»¶è¿Ÿ: {{ performanceStats.avgProcessTime }}ms
                        </el-text>
                      </div>
                      <div class="performance-advice" v-if="performanceStats.avgProcessTime > 0">
                        <el-alert
                          :title="getPerformanceAdvice().title"
                          :description="getPerformanceAdvice().advice"
                          :type="getPerformanceAdvice().level"
                          :closable="false"
                          size="small"
                          show-icon
                        />
                      </div>
                    </div>
                  </el-form-item>
                  
                  <el-form-item label="æ£€æµ‹æ¡†æµ‹è¯•" v-if="isStreaming">
                    <div class="test-controls">
                      <el-button 
                        type="primary" 
                        size="small" 
                        @click="testDetectionBoxes"
                        :icon="Search"
                      >
                        æµ‹è¯•æ£€æµ‹æ¡†æ˜¾ç¤º
                      </el-button>
                      <el-button 
                        type="warning" 
                        size="small" 
                        @click="clearDetectionBoxes"
                        :icon="Close"
                      >
                        æ¸…é™¤æ£€æµ‹æ¡†
                      </el-button>
                      <el-button 
                        type="danger" 
                        size="small" 
                        @click="resetDetectionCache"
                        :icon="Refresh"
                      >
                        é‡ç½®è·Ÿè¸ª
                      </el-button>
                      <el-text type="info" size="small">
                        å¦‚æœæ£€æµ‹æ¡†å¼‚å¸¸ï¼Œå¯å°è¯•é‡ç½®è·Ÿè¸ªç¼“å­˜
                      </el-text>
                    </div>
                  </el-form-item>
                  
                  <el-form-item label="éŸ³é¢‘ç›‘æ§" v-if="aiSettings.soundDetection && isStreaming">
                    <div class="audio-monitor">
                      <div class="audio-level-display">
                        <span class="audio-text">éŸ³é‡: {{ performanceStats.audioLevel }}%</span>
                        <div class="audio-bar">
                          <div 
                            class="audio-level" 
                            :style="{ 
                              width: performanceStats.audioLevel + '%',
                              backgroundColor: performanceStats.audioLevel > 50 ? '#f56c6c' : '#67c23a'
                            }"
                          ></div>
                        </div>
                      </div>
                    </div>
                  </el-form-item>
                </el-form>
              </div>
            </el-card>

            <!-- å®æ—¶æ£€æµ‹ç»“æœ -->
            <el-card class="results-panel" shadow="never">
              <template #header>
                <div class="card-header">
                  <span>ğŸ” æ£€æµ‹ç»“æœ</span>
                  <el-badge :value="detectionResults.length" class="badge" />
                </div>
              </template>
              
              <el-scrollbar height="300px">
                <div class="detection-list">
                  <div 
                    v-for="(result, index) in detectionResults" 
                    :key="index"
                    class="detection-item"
                    :class="`type-${result.type}`"
                  >
                    <div class="detection-icon">
                      {{ getDetectionIcon(result.type) }}
                    </div>
                    <div class="detection-info">
                      <div class="detection-name">{{ result.label }}</div>
                      <div class="detection-details">
                        ç½®ä¿¡åº¦: {{ (result.confidence * 100).toFixed(1) }}%
                      </div>
                      <div class="detection-time">
                        {{ formatTime(result.timestamp) }}
                      </div>
                    </div>
                  </div>
                  
                  <div v-if="detectionResults.length === 0" class="no-results">
                    <el-icon><Search /></el-icon>
                    <p>æš‚æ— æ£€æµ‹ç»“æœ</p>
                  </div>
                </div>
              </el-scrollbar>
            </el-card>

            <!-- æ€§èƒ½ç›‘æ§ -->
            <el-card class="performance-panel" shadow="never" v-show="aiAnalysisEnabled">
              <template #header>
                <span>ğŸ“Š æ€§èƒ½ç›‘æ§</span>
              </template>
              
              <div class="performance-stats">
                <div class="stat-item">
                  <span class="stat-label">æ£€æµ‹FPS</span>
                  <span class="stat-value">{{ performanceStats.fps }}</span>
                </div>
                <div class="stat-item">
                  <span class="stat-label">å¹³å‡å»¶è¿Ÿ</span>
                  <span class="stat-value">{{ performanceStats.avgProcessTime }}ms</span>
                </div>
                <div class="stat-item">
                  <span class="stat-label">å¹¶å‘è·³è¿‡</span>
                  <span class="stat-value">{{ performanceStats.skippedFrames }}</span>
                </div>
                <div class="stat-item">
                  <span class="stat-label">æ— å˜åŒ–è·³è¿‡</span>
                  <span class="stat-value">{{ performanceStats.motionSkippedFrames }}</span>
                </div>
                <div class="stat-item" v-if="aiSettings.soundDetection">
                  <span class="stat-label">éŸ³é‡çº§åˆ«</span>
                  <span class="stat-value">{{ performanceStats.audioLevel }}%</span>
                </div>
              </div>
            </el-card>

            <!-- å®æ—¶å‘Šè­¦ -->
            <el-card class="alerts-panel" shadow="never">
              <template #header>
                <div class="card-header">
                  <span>âš ï¸ å®æ—¶å‘Šè­¦</span>
                  <el-badge :value="realtimeAlerts.length" class="badge" type="danger" />
                </div>
              </template>
              
              <el-scrollbar height="200px">
                <div class="alerts-list">
                  <el-alert
                    v-for="(alert, index) in realtimeAlerts"
                    :key="index"
                    :title="alert.title"
                    :description="alert.description"
                    :type="alert.type"
                    :closable="true"
                    @close="removeAlert(index)"
                    class="alert-item"
                  />
                  
                  <div v-if="realtimeAlerts.length === 0" class="no-alerts">
                    <el-icon><SuccessFilled /></el-icon>
                    <p>æš‚æ— å‘Šè­¦</p>
                  </div>
                </div>
              </el-scrollbar>
            </el-card>
          </el-col>
        </el-row>
      </el-main>
    </el-container>
  </div>
</template>

<script setup>
import { ref, reactive, onMounted, onUnmounted, nextTick, watch } from 'vue'
import { ElMessage, ElNotification } from 'element-plus'
import {
  VideoCamera,
  Close,
  Cpu,
  Search,
  SuccessFilled,
  Refresh
} from '@element-plus/icons-vue'

// å“åº”å¼æ•°æ®
const videoElement = ref(null)
const overlayCanvas = ref(null)
const videoContainer = ref(null)
const isStreaming = ref(false)
const aiAnalysisEnabled = ref(false)
const selectedDeviceId = ref('')
const videoDevices = ref([])
const analysisInterval = ref(300) // åˆ†æé—´éš”ï¼ˆæ¯«ç§’ï¼‰- å¹³è¡¡æ€§èƒ½ä¸å®æ—¶æ€§ï¼Œé»˜è®¤æ›´å¿«

// AIè®¾ç½®
const aiSettings = reactive({
  faceRecognition: true,
  objectDetection: true,
  behaviorAnalysis: true,
  soundDetection: true,
  realtimeMode: false  // å®æ—¶æ¨¡å¼ï¼šæ›´é«˜çš„æ£€æµ‹é¢‘ç‡
})

// æ£€æµ‹ç»“æœå’Œå‘Šè­¦
const detectionResults = ref([])
const realtimeAlerts = ref([])
const lastFrameDetections = ref([]) // ç¼“å­˜ä¸Šä¸€å¸§çš„æ£€æµ‹ç»“æœç”¨äºå¹³æ»‘

// å†…éƒ¨å˜é‡
let mediaStream = null
let analysisTimer = null
let canvasContext = null
let cameraId = 'webcam_monitor'

// å‘Šè­¦å»é‡æœºåˆ¶
const alertCooldowns = new Map() // å­˜å‚¨å„ç±»å‹å‘Šè­¦çš„å†·å´æ—¶é—´
const ALERT_COOLDOWN = 5000 // 5ç§’å†·å´æ—¶é—´ï¼Œé¿å…é¢‘ç¹å¼¹çª—
let isProcessingFrame = false // é˜²æ­¢å¹¶å‘å¤„ç†å¸§

// æ€§èƒ½ä¼˜åŒ–ç›¸å…³
let lastFrameData = null // ä¸Šä¸€å¸§çš„å›¾åƒæ•°æ®ï¼Œç”¨äºå¸§å·®æ£€æµ‹
let audioContext = null // éŸ³é¢‘ä¸Šä¸‹æ–‡ï¼Œç”¨äºéŸ³é‡æ£€æµ‹
let audioAnalyser = null // éŸ³é¢‘åˆ†æå™¨
let audioDataArray = null // éŸ³é¢‘æ•°æ®æ•°ç»„
const MOTION_THRESHOLD = 0.015 // å¸§å·®é˜ˆå€¼ï¼Œæ›´æ•æ„Ÿçš„æ£€æµ‹
const MAX_ACCEPTABLE_DELAY = 300 // æœ€å¤§å¯æ¥å—å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
let consecutiveSlowFrames = 0 // è¿ç»­æ…¢å¸§è®¡æ•°
let currentImageScale = 1 // å½“å‰å›¾åƒç¼©æ”¾æ¯”ä¾‹ï¼Œç”¨äºåæ ‡è½¬æ¢

// æ€§èƒ½ç›‘æ§
const performanceStats = reactive({
  fps: 0,
  avgProcessTime: 0,
  processedFrames: 0,
  skippedFrames: 0,
  motionSkippedFrames: 0, // å› ä¸ºæ— å˜åŒ–è€Œè·³è¿‡çš„å¸§
  audioLevel: 0 // å½“å‰éŸ³é‡çº§åˆ«
})

let frameProcessTimes = []
let lastStatsUpdate = Date.now()

// è·å–å¯ç”¨æ‘„åƒå¤´è®¾å¤‡
const getVideoDevices = async () => {
  try {
    const devices = await navigator.mediaDevices.enumerateDevices()
    videoDevices.value = devices.filter(device => device.kind === 'videoinput')
    if (videoDevices.value.length > 0 && !selectedDeviceId.value) {
      selectedDeviceId.value = videoDevices.value[0].deviceId
    }
  } catch (error) {
    console.error('è·å–æ‘„åƒå¤´è®¾å¤‡å¤±è´¥:', error)
    ElMessage.error('æ— æ³•è·å–æ‘„åƒå¤´è®¾å¤‡åˆ—è¡¨')
  }
}

// åˆå§‹åŒ–éŸ³é¢‘åˆ†æ
const initAudioAnalysis = async (stream) => {
  try {
    audioContext = new (window.AudioContext || window.webkitAudioContext)()
    audioAnalyser = audioContext.createAnalyser()
    audioAnalyser.fftSize = 256
    
    const source = audioContext.createMediaStreamSource(stream)
    source.connect(audioAnalyser)
    
    audioDataArray = new Uint8Array(audioAnalyser.frequencyBinCount)
    
    // å¼€å§‹éŸ³é¢‘ç›‘æ§
    startAudioMonitoring()
    
  } catch (error) {
    console.error('éŸ³é¢‘åˆ†æåˆå§‹åŒ–å¤±è´¥:', error)
  }
}

// å¼€å§‹éŸ³é¢‘ç›‘æ§
const startAudioMonitoring = () => {
  const monitorAudio = () => {
    if (!audioAnalyser || !audioDataArray) return
    
    audioAnalyser.getByteFrequencyData(audioDataArray)
    
    // è®¡ç®—å¹³å‡éŸ³é‡
    const average = audioDataArray.reduce((sum, value) => sum + value, 0) / audioDataArray.length
    performanceStats.audioLevel = Math.round(average / 255 * 100)
    
    // æ£€æµ‹å¼‚å¸¸éŸ³é‡
    if (average > 100) { // é˜ˆå€¼å¯è°ƒæ•´
      const now = Date.now()
      const alertKey = 'audio_volume_high'
      
      if (!alertCooldowns.has(alertKey) || now - alertCooldowns.get(alertKey) > ALERT_COOLDOWN) {
        addAlert({
          title: 'ğŸ”Š æ£€æµ‹åˆ°é«˜éŸ³é‡',
          description: `éŸ³é‡çº§åˆ«: ${performanceStats.audioLevel}%`,
          type: 'warning'
        })
        
        // å‘é€éŸ³é¢‘å‘Šè­¦åˆ°AIæœåŠ¡
        sendAudioAlertToAI(performanceStats.audioLevel, 'high_volume')
        
        alertCooldowns.set(alertKey, now)
      }
    }
    
    requestAnimationFrame(monitorAudio)
  }
  
  monitorAudio()
}

// è¶…é«˜æ•ˆå¸§å·®æ£€æµ‹ - åˆ¤æ–­ç”»é¢æ˜¯å¦æœ‰æ˜¾è‘—å˜åŒ–
const hasSignificantMotion = (currentImageData, lastImageData) => {
  if (!lastImageData) return true // ç¬¬ä¸€å¸§æ€»æ˜¯å‘é€
  
  const threshold = MOTION_THRESHOLD
  let diffPixels = 0
  const sampleCount = Math.min(500, Math.floor(currentImageData.length / 32)) // é™åˆ¶é‡‡æ ·æ•°é‡
  const step = Math.max(32, Math.floor(currentImageData.length / sampleCount))
  
  // è¶…çº§ç¨€ç–é‡‡æ ·æ£€æµ‹ï¼Œå¤§å¹…æé«˜æ€§èƒ½
  for (let i = 0; i < currentImageData.length; i += step) {
    if (i + 2 >= currentImageData.length || i + 2 >= lastImageData.length) break
    
    // ä½¿ç”¨äº®åº¦å·®å¼‚æ£€æµ‹ï¼ˆæ›´é«˜æ•ˆï¼‰
    const currentBrightness = (currentImageData[i] + currentImageData[i + 1] + currentImageData[i + 2]) / 3
    const lastBrightness = (lastImageData[i] + lastImageData[i + 1] + lastImageData[i + 2]) / 3
    
    if (Math.abs(currentBrightness - lastBrightness) > 20) { // äº®åº¦å·®å¼‚é˜ˆå€¼
      diffPixels++
    }
  }
  
  const motionRatio = diffPixels / sampleCount
  return motionRatio > threshold
}

// å¯åŠ¨æœ¬åœ°æ‘„åƒå¤´
const startLocalCamera = async () => {
  try {
    const constraints = {
      video: {
        deviceId: selectedDeviceId.value ? { exact: selectedDeviceId.value } : undefined,
        width: { ideal: 1280 },
        height: { ideal: 720 },
        facingMode: 'user'
      },
      audio: aiSettings.soundDetection
    }

    mediaStream = await navigator.mediaDevices.getUserMedia(constraints)
    videoElement.value.srcObject = mediaStream
    isStreaming.value = true

    // å¦‚æœå¯ç”¨äº†å£°éŸ³æ£€æµ‹ï¼Œåˆå§‹åŒ–éŸ³é¢‘åˆ†æ
    if (aiSettings.soundDetection && mediaStream.getAudioTracks().length > 0) {
      await initAudioAnalysis(mediaStream)
    }

    ElMessage.success('æ‘„åƒå¤´å¯åŠ¨æˆåŠŸï¼')
    
    // å¯åŠ¨AIåˆ†ææµ
    await startAIStream()
    
  } catch (error) {
    console.error('å¯åŠ¨æ‘„åƒå¤´å¤±è´¥:', error)
    ElMessage.error('å¯åŠ¨æ‘„åƒå¤´å¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®')
  }
}

// åœæ­¢æ‘„åƒå¤´
const stopCamera = async () => {
  try {
    // åœæ­¢AIåˆ†æ
    await stopAIStream()
    
    // åœæ­¢åª’ä½“æµ
    if (mediaStream) {
      mediaStream.getTracks().forEach(track => track.stop())
      mediaStream = null
    }
    
    if (videoElement.value) {
      videoElement.value.srcObject = null
    }
    
    isStreaming.value = false
    aiAnalysisEnabled.value = false
    detectionResults.value = []
    realtimeAlerts.value = []
    lastFrameDetections.value = [] // æ¸…é™¤æ£€æµ‹ç¼“å­˜
    
    // é‡ç½®æ€§èƒ½ç»Ÿè®¡
    performanceStats.fps = 0
    performanceStats.avgProcessTime = 0
    performanceStats.processedFrames = 0
    performanceStats.skippedFrames = 0
    performanceStats.motionSkippedFrames = 0
    performanceStats.audioLevel = 0
    frameProcessTimes = []
    isProcessingFrame = false
    
    // æ¸…ç†éŸ³é¢‘ç›¸å…³èµ„æº
    if (audioContext) {
      audioContext.close()
      audioContext = null
    }
    audioAnalyser = null
    audioDataArray = null
    lastFrameData = null
    
    // æ¸…é™¤å‘Šè­¦å†·å´æ—¶é—´
    alertCooldowns.clear()
    
    // æ¸…é™¤ç”»å¸ƒ
    if (canvasContext) {
      canvasContext.clearRect(0, 0, overlayCanvas.value.width, overlayCanvas.value.height)
    }
    
    ElMessage.success('æ‘„åƒå¤´å·²åœæ­¢')
  } catch (error) {
    console.error('åœæ­¢æ‘„åƒå¤´å¤±è´¥:', error)
    ElMessage.error('åœæ­¢æ‘„åƒå¤´å¤±è´¥')
  }
}

// å¯åŠ¨AIåˆ†ææµ
const startAIStream = async () => {
  try {
    const response = await fetch(`http://localhost:8001/stream/webcam/start/${cameraId}`, {
      method: 'GET'
    })

    if (response.ok) {
      aiAnalysisEnabled.value = true
      startFrameCapture()
      ElMessage.success('AIåˆ†æå·²å¯åŠ¨')
    } else {
      throw new Error('AIæœåŠ¡å“åº”é”™è¯¯')
    }
  } catch (error) {
    console.error('å¯åŠ¨AIåˆ†æå¤±è´¥:', error)
    ElMessage.error('å¯åŠ¨AIåˆ†æå¤±è´¥ï¼Œè¯·ç¡®ä¿AIæœåŠ¡æ­£åœ¨è¿è¡Œ')
  }
}

// åœæ­¢AIåˆ†ææµ
const stopAIStream = async () => {
  try {
    if (analysisTimer) {
      clearInterval(analysisTimer)
      analysisTimer = null
    }

    const response = await fetch(`http://localhost:8001/stream/webcam/stop/${cameraId}`, {
      method: 'POST'
    })

    if (response.ok) {
      aiAnalysisEnabled.value = false
      // åœæ­¢AIåˆ†ææ—¶æ¸…é™¤æ£€æµ‹æ¡†
      clearDetectionBoxes()
      ElMessage.info('AIåˆ†æå·²åœæ­¢')
    }
  } catch (error) {
    console.error('åœæ­¢AIåˆ†æå¤±è´¥:', error)
  }
}

// å¼€å§‹å¸§æ•è·å’Œåˆ†æ
const startFrameCapture = () => {
  if (analysisTimer) {
    clearTimeout(analysisTimer)
  }



  const scheduleNextCapture = () => {
    if (!isStreaming.value || !aiAnalysisEnabled.value) return
    
    const interval = getDynamicInterval()
    analysisTimer = setTimeout(async () => {
      await captureAndAnalyze()
      scheduleNextCapture()  // é€’å½’è°ƒåº¦ä¸‹ä¸€æ¬¡æ•è·
    }, interval)
  }

  const captureAndAnalyze = async () => {
    if (!isStreaming.value || !aiAnalysisEnabled.value || !videoElement.value) {
      return
    }

    // é˜²æ­¢å¹¶å‘å¤„ç†ï¼Œè·³è¿‡æ­£åœ¨å¤„ç†çš„å¸§ï¼ˆå®æ—¶æ¨¡å¼ä¸‹å‡å°‘è·³è¿‡ï¼‰
    if (isProcessingFrame) {
      performanceStats.skippedFrames++
      // å®æ—¶æ¨¡å¼ä¸‹å…è®¸æ›´å¤šå¹¶å‘ï¼Œé™ä½è·³å¸§ç‡
      if (!aiSettings.realtimeMode) {
        return
      }
      // å®æ—¶æ¨¡å¼ä¸‹åªåœ¨å»¶è¿Ÿè¿‡é«˜æ—¶æ‰è·³å¸§
      if (performanceStats.avgProcessTime > 400) {
        return
      }
    }

    try {
      isProcessingFrame = true
      
      // æ•è·å½“å‰å¸§
      const canvas = document.createElement('canvas')
      const video = videoElement.value
      
      // æ›´æ¿€è¿›çš„åŠ¨æ€åˆ†è¾¨ç‡è°ƒæ•´
      let scale = 1
      if (performanceStats.avgProcessTime > 400) {
        scale = 0.3  // è¶…é«˜å»¶è¿Ÿæ—¶ä½¿ç”¨æä½åˆ†è¾¨ç‡
        consecutiveSlowFrames++
      } else if (performanceStats.avgProcessTime > 300) {
        scale = 0.4  // é«˜å»¶è¿Ÿæ—¶ä½¿ç”¨å¾ˆä½åˆ†è¾¨ç‡
        consecutiveSlowFrames++
      } else if (performanceStats.avgProcessTime > 200) {
        scale = 0.5  // ä¸­å»¶è¿Ÿæ—¶ä½¿ç”¨ä½åˆ†è¾¨ç‡
        consecutiveSlowFrames = Math.max(0, consecutiveSlowFrames - 1)
      } else {
        scale = performanceStats.avgProcessTime > 100 ? 0.7 : 0.8  // æ­£å¸¸æƒ…å†µ
        consecutiveSlowFrames = 0
      }
      
      // å¦‚æœè¿ç»­å¤šå¸§éƒ½å¾ˆæ…¢ï¼Œè¿›ä¸€æ­¥é™ä½è´¨é‡
      if (consecutiveSlowFrames > 3) {
        scale = Math.max(0.2, scale * 0.8)
      }
      
      // ä¿å­˜å½“å‰ç¼©æ”¾æ¯”ä¾‹ç”¨äºåæ ‡è½¬æ¢
      currentImageScale = scale
      
      canvas.width = Math.floor(video.videoWidth * scale)
      canvas.height = Math.floor(video.videoHeight * scale)
      
      const ctx = canvas.getContext('2d')
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height)
      
      // è·å–å½“å‰å¸§æ•°æ®ç”¨äºå¸§å·®æ£€æµ‹ï¼ˆä½¿ç”¨é™é‡‡æ ·æé«˜é€Ÿåº¦ï¼‰
      const sampleWidth = Math.max(50, Math.floor(canvas.width / 8))
      const sampleHeight = Math.max(50, Math.floor(canvas.height / 8))
      const currentImageData = ctx.getImageData(0, 0, sampleWidth, sampleHeight).data
      
      // æ£€æµ‹ç”»é¢å˜åŒ–ï¼ˆå®æ—¶æ¨¡å¼ä¸‹é™ä½è·³å¸§æ¦‚ç‡ï¼‰
      if (!aiSettings.realtimeMode && !hasSignificantMotion(currentImageData, lastFrameData)) {
        performanceStats.motionSkippedFrames++
        isProcessingFrame = false
        return // ç”»é¢æ— æ˜¾è‘—å˜åŒ–ï¼Œè·³è¿‡æ­¤å¸§ï¼ˆå®æ—¶æ¨¡å¼ä¸‹ä¸è·³å¸§ï¼‰
      }
      
      // ä¿å­˜å½“å‰å¸§æ•°æ®ä½œä¸ºä¸‹ä¸€æ¬¡æ¯”è¾ƒçš„åŸºå‡†
      lastFrameData = new Uint8ClampedArray(currentImageData)
      
      // æè‡´çš„ç”»è´¨ä¼˜åŒ– - æ ¹æ®å»¶è¿Ÿæ¿€è¿›è°ƒæ•´
      let quality = 0.4  // é»˜è®¤è¾ƒä½ç”»è´¨
      if (performanceStats.avgProcessTime > 500) {
        quality = 0.2  // è¶…é«˜å»¶è¿Ÿæ—¶ä½¿ç”¨æä½ç”»è´¨
      } else if (performanceStats.avgProcessTime > 350) {
        quality = 0.3  // é«˜å»¶è¿Ÿæ—¶ä½¿ç”¨å¾ˆä½ç”»è´¨
      } else if (performanceStats.avgProcessTime > 200) {
        quality = 0.4  // ä¸­å»¶è¿Ÿæ—¶ä½¿ç”¨ä½ç”»è´¨
      } else {
        quality = 0.5  // æ­£å¸¸æƒ…å†µç¨å¾®æé«˜ç”»è´¨
      }
      
      // è½¬æ¢ä¸ºblobå¹¶å‘é€åˆ°AIæœåŠ¡
      canvas.toBlob(async (blob) => {
        if (blob) {
          try {
            await sendFrameToAI(blob)
          } finally {
            isProcessingFrame = false
          }
        } else {
          isProcessingFrame = false
        }
      }, 'image/jpeg', quality)
      
    } catch (error) {
      console.error('å¸§æ•è·å¤±è´¥:', error)
      isProcessingFrame = false
    }
  }

  // å¼€å§‹ç¬¬ä¸€æ¬¡æ•è·
  scheduleNextCapture()
}

// å‘é€å¸§åˆ°AIæœåŠ¡è¿›è¡Œåˆ†æ
const sendFrameToAI = async (frameBlob) => {
  const startTime = performance.now()
  
  try {
    const formData = new FormData()
    formData.append('frame', frameBlob, 'frame.jpg')
    formData.append('camera_id', cameraId)
    formData.append('enable_face_recognition', aiSettings.faceRecognition)
    formData.append('enable_object_detection', aiSettings.objectDetection)
    formData.append('enable_behavior_detection', aiSettings.behaviorAnalysis)

    // åˆ›å»ºAbortControlleræ¥æ§åˆ¶è¯·æ±‚è¶…æ—¶
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), 3000) // 3ç§’è¶…æ—¶

    const response = await fetch('http://localhost:8001/frame/analyze/', {
      method: 'POST',
      body: formData,
      signal: controller.signal
    })

    clearTimeout(timeoutId)

    if (response.ok) {
      const result = await response.json()
      if (result.status === 'success') {
        processAIResults(result.results)
        
        // æ›´æ–°æ€§èƒ½ç»Ÿè®¡
        const processTime = performance.now() - startTime
        updatePerformanceStats(processTime, true)
      }
    } else {
      console.warn('AIæœåŠ¡å“åº”å¼‚å¸¸:', response.status)
    }
    
  } catch (error) {
    if (error.name === 'AbortError') {
      console.warn('AIè¯·æ±‚è¶…æ—¶ï¼Œè·³è¿‡æ­¤å¸§')
    } else {
      console.error('å‘é€å¸§åˆ°AIæœåŠ¡å¤±è´¥:', error)
    }
    // æ›´æ–°æ€§èƒ½ç»Ÿè®¡ï¼ˆå¤±è´¥çš„è¯·æ±‚ï¼‰
    const processTime = performance.now() - startTime
    updatePerformanceStats(processTime, false)
  }
}

// æ›´æ–°æ€§èƒ½ç»Ÿè®¡
const updatePerformanceStats = (processTime, success) => {
  if (success) {
    performanceStats.processedFrames++
    frameProcessTimes.push(processTime)
    
    // ä¿æŒæœ€è¿‘100æ¬¡çš„å¤„ç†æ—¶é—´
    if (frameProcessTimes.length > 100) {
      frameProcessTimes.shift()
    }
    
    // è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´
    const avgTime = frameProcessTimes.reduce((a, b) => a + b, 0) / frameProcessTimes.length
    performanceStats.avgProcessTime = Math.round(avgTime)
  }
  
  // æ¯5ç§’æ›´æ–°ä¸€æ¬¡FPS
  const now = Date.now()
  if (now - lastStatsUpdate > 5000) {
    const timeDiff = (now - lastStatsUpdate) / 1000
    performanceStats.fps = Math.round(performanceStats.processedFrames / timeDiff * 10) / 10
    
    // é‡ç½®è®¡æ•°å™¨
    performanceStats.processedFrames = 0
    performanceStats.skippedFrames = 0
    performanceStats.motionSkippedFrames = 0
    lastStatsUpdate = now
  }
}

// å¤„ç†AIåˆ†æç»“æœ
const processAIResults = (results) => {
  if (!results || !results.detections) return
  
  const detections = []
  
  // å¤„ç†æ£€æµ‹ç»“æœ
  results.detections.forEach(detection => {
    const processedDetection = {
      type: detection.type,
      label: getDetectionLabel(detection),
      confidence: detection.confidence,
      bbox: detection.bbox,
      timestamp: new Date(detection.timestamp)
    }
    detections.push(processedDetection)
  })
  
  // å¤„ç†å‘Šè­¦
  if (results.alerts && results.alerts.length > 0) {
    results.alerts.forEach(alert => {
      addAlert({
        title: getAlertTitle(alert.type),
        description: alert.message,
        type: getAlertType(alert.type)
      })
    })
  }
  
  // æ€»æ˜¯æ›´æ–°æ£€æµ‹ç»“æœï¼Œå³ä½¿ä¸ºç©ºï¼ˆè¿™æ ·å¯ä»¥æ¸…é™¤ä¹‹å‰çš„æ£€æµ‹æ¡†ï¼‰
  updateDetectionResults(detections)
  drawDetectionResults(detections)
}

// è·å–æ£€æµ‹æ ‡ç­¾
const getDetectionLabel = (detection) => {
  if (detection.type === 'object') {
    return detection.class_name
  } else if (detection.type === 'face') {
    return detection.known ? detection.name : 'æœªçŸ¥äººè„¸'
  }
  return 'æœªçŸ¥'
}

// è·å–å‘Šè­¦æ ‡é¢˜
const getAlertTitle = (alertType) => {
  const titles = {
    person_detected: 'ğŸš¨ æ£€æµ‹åˆ°äººå‘˜',
    unknown_face: 'âš ï¸ å‘ç°æœªçŸ¥äººè„¸',
    behavior_anomaly: 'ğŸ”¥ å¼‚å¸¸è¡Œä¸ºæ£€æµ‹'
  }
  return titles[alertType] || 'ğŸ”” æ£€æµ‹å‘Šè­¦'
}

// è·å–å‘Šè­¦ç±»å‹
const getAlertType = (alertType) => {
  const types = {
    person_detected: 'info',
    unknown_face: 'warning',
    behavior_anomaly: 'error'
  }
  return types[alertType] || 'info'
}

// æ¨¡æ‹ŸAIåˆ†æç»“æœï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
const simulateAIResults = () => {
  // æ¨¡æ‹Ÿæ£€æµ‹ç»“æœ
  if (Math.random() > 0.7) {
    const mockResults = [
      {
        type: 'person',
        label: 'äººå‘˜',
        confidence: 0.85 + Math.random() * 0.15,
        bbox: [
          Math.random() * 200,
          Math.random() * 200,
          200 + Math.random() * 300,
          200 + Math.random() * 400
        ],
        timestamp: new Date()
      }
    ]
    
    if (Math.random() > 0.8) {
      mockResults.push({
        type: 'face',
        label: 'æœªçŸ¥äººè„¸',
        confidence: 0.75 + Math.random() * 0.25,
        bbox: [
          mockResults[0].bbox[0] + 50,
          mockResults[0].bbox[1] + 20,
          mockResults[0].bbox[0] + 150,
          mockResults[0].bbox[1] + 120
        ],
        timestamp: new Date()
      })
      
      // ç”Ÿæˆå‘Šè­¦
      addAlert({
        title: 'âš ï¸ æ£€æµ‹åˆ°æœªçŸ¥äººå‘˜',
        description: `ç½®ä¿¡åº¦: ${(mockResults[1].confidence * 100).toFixed(1)}%`,
        type: 'warning'
      })
    }
    
    updateDetectionResults(mockResults)
    drawDetectionResults(mockResults)
  }
}

// è®¡ç®—ä¸¤ä¸ªæ£€æµ‹æ¡†çš„è·ç¦»ï¼ˆç”¨äºåŒ¹é…ï¼‰
const calculateDistance = (bbox1, bbox2) => {
  const center1 = [(bbox1[0] + bbox1[2]) / 2, (bbox1[1] + bbox1[3]) / 2]
  const center2 = [(bbox2[0] + bbox2[2]) / 2, (bbox2[1] + bbox2[3]) / 2]
  return Math.sqrt(Math.pow(center1[0] - center2[0], 2) + Math.pow(center1[1] - center2[1], 2))
}

// ä¼˜åŒ–çš„å¹³æ»‘æ£€æµ‹æ¡†ä½ç½®ï¼ˆé…åˆAIç«¯ç¨³å®šåŒ–ï¼‰
const smoothDetections = (newDetections, lastDetections) => {
  if (!lastDetections || lastDetections.length === 0) {
    return newDetections.map(det => ({
      ...det,
      isStable: det.is_stable || false
    }))
  }

  const smoothedResults = []
  const MATCH_THRESHOLD = 100 // é™ä½åŒ¹é…é˜ˆå€¼ï¼ŒAIç«¯å·²åšç¨³å®šåŒ–
  
  // æ ¹æ®AIç«¯çš„ç¨³å®šæ€§æ ‡è®°è°ƒæ•´å¹³æ»‘å› å­
  const getSmoothFactor = (detection) => {
    if (detection.is_stable) {
      return aiSettings.realtimeMode ? 0.8 : 0.6 // ç¨³å®šç›®æ ‡æ›´å¹³æ»‘
    } else {
      return aiSettings.realtimeMode ? 0.9 : 0.8 // æ–°ç›®æ ‡å“åº”æ›´å¿«
    }
  }

  newDetections.forEach(newDet => {
    let bestMatch = null
    let minDistance = Infinity

    // å¯»æ‰¾æœ€ä½³åŒ¹é…
    lastDetections.forEach(lastDet => {
      if (newDet.type === lastDet.type) {
        const distance = calculateDistance(newDet.bbox, lastDet.bbox)
        if (distance < MATCH_THRESHOLD && distance < minDistance) {
          minDistance = distance
          bestMatch = lastDet
        }
      }
    })

    if (bestMatch && !newDet.is_kept) { // å¦‚æœä¸æ˜¯AIä¿ç•™çš„å¯¹è±¡æ‰å‰ç«¯å¹³æ»‘
      const smoothFactor = getSmoothFactor(newDet)
      
      const smoothedBbox = [
        bestMatch.bbox[0] + (newDet.bbox[0] - bestMatch.bbox[0]) * smoothFactor,
        bestMatch.bbox[1] + (newDet.bbox[1] - bestMatch.bbox[1]) * smoothFactor,
        bestMatch.bbox[2] + (newDet.bbox[2] - bestMatch.bbox[2]) * smoothFactor,
        bestMatch.bbox[3] + (newDet.bbox[3] - bestMatch.bbox[3]) * smoothFactor
      ]
      
      smoothedResults.push({
        ...newDet,
        bbox: smoothedBbox,
        isStable: newDet.is_stable || true // ç»§æ‰¿AIç«¯çš„ç¨³å®šæ€§æ ‡è®°
      })
    } else {
      // AIç«¯å·²å¤„ç†æˆ–æ–°ç›®æ ‡ï¼Œç›´æ¥ä½¿ç”¨
      smoothedResults.push({
        ...newDet,
        isStable: newDet.is_stable || false
      })
    }
  })

  return smoothedResults
}

// æ›´æ–°æ£€æµ‹ç»“æœåˆ—è¡¨ - å¸¦å¹³æ»‘å¤„ç†
const updateDetectionResults = (results) => {
  // å¯¹æ£€æµ‹ç»“æœè¿›è¡Œå¹³æ»‘å¤„ç†
  const smoothedResults = smoothDetections(results, lastFrameDetections.value)
  
  // æ›´æ–°å½“å‰å¸§ç»“æœ
  detectionResults.value = smoothedResults.slice(0, 20) // ä»…æ˜¾ç¤ºæœ€æ–°çš„20ä¸ªæ£€æµ‹ç»“æœ
  
  // ç¼“å­˜å½“å‰å¸§ç»“æœä¾›ä¸‹ä¸€å¸§ä½¿ç”¨
  lastFrameDetections.value = smoothedResults.slice()
}

// åœ¨è§†é¢‘ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
const drawDetectionResults = (results) => {
  if (!canvasContext || !overlayCanvas.value || !videoElement.value) {
    console.log('ç»˜åˆ¶æ¡ä»¶ä¸æ»¡è¶³:', { canvasContext, overlayCanvas: overlayCanvas.value, videoElement: videoElement.value })
    return
  }

  // æ¸…é™¤ä¹‹å‰çš„æ£€æµ‹æ¡†
  canvasContext.clearRect(0, 0, overlayCanvas.value.width, overlayCanvas.value.height)

  // è·å–å„ç§å°ºå¯¸ä¿¡æ¯
  const canvasWidth = overlayCanvas.value.width
  const canvasHeight = overlayCanvas.value.height
  const videoWidth = videoElement.value.videoWidth || canvasWidth
  const videoHeight = videoElement.value.videoHeight || canvasHeight
  
  // æ£€æµ‹çŠ¶æ€æ—¥å¿—
  if (results.length > 0) {
    const stableCount = results.filter(r => r.isStable || r.is_stable).length
    const keptCount = results.filter(r => r.is_kept).length
    console.log(`ğŸ¯ æ£€æµ‹: ${results.length}ä¸ªç›®æ ‡ (ç¨³å®š:${stableCount}, ä¿ç•™:${keptCount})`)
  }

  results.forEach((result, index) => {
    if (result.bbox && result.bbox.length === 4) {
      // AIè¿”å›çš„åæ ‡æ˜¯åŸºäºç¼©æ”¾åå›¾åƒçš„ï¼Œéœ€è¦ç›´æ¥è½¬æ¢åˆ°Canvasæ˜¾ç¤ºåæ ‡
      const [x1, y1, x2, y2] = result.bbox
      
      // è®¡ç®—æ­£ç¡®çš„è½¬æ¢æ¯”ä¾‹ï¼š
      // AIåæ ‡åŸºäº: (videoWidth * currentImageScale) x (videoHeight * currentImageScale)
      // Canvasæ˜¾ç¤ºåŸºäº: canvasWidth x canvasHeight
      const scaledVideoWidth = videoWidth * currentImageScale
      const scaledVideoHeight = videoHeight * currentImageScale
      
      const scaleX = canvasWidth / scaledVideoWidth
      const scaleY = canvasHeight / scaledVideoHeight
      
      const displayX1 = x1 * scaleX
      const displayY1 = y1 * scaleY
      const displayX2 = x2 * scaleX
      const displayY2 = y2 * scaleY
      
      const width = displayX2 - displayX1
      const height = displayY2 - displayY1

      // æ ¹æ®ç›®æ ‡çŠ¶æ€ç»˜åˆ¶ä¸åŒæ ·å¼çš„æ£€æµ‹æ¡†
      const color = getDetectionColor(result.type)
      canvasContext.strokeStyle = color
      
      // æ ¹æ®ç›®æ ‡çŠ¶æ€è®¾ç½®çº¿æ¡æ ·å¼
      if (result.is_kept) {
        // AIä¿ç•™çš„å¯¹è±¡ï¼šè™šçº¿æ¡†è¡¨ç¤ºé¢„æµ‹ä¿æŒ
        canvasContext.setLineDash([8, 4])
        canvasContext.lineWidth = 3
        canvasContext.globalAlpha = 0.8
      } else if (result.isStable || result.is_stable) {
        // ç¨³å®šç›®æ ‡ï¼šç²—å®çº¿
        canvasContext.setLineDash([])
        canvasContext.lineWidth = 4
        canvasContext.globalAlpha = 1.0
      } else {
        // æ–°ç›®æ ‡ï¼šç»†å®çº¿
        canvasContext.setLineDash([])
        canvasContext.lineWidth = 2
        canvasContext.globalAlpha = 0.9
      }
      
      canvasContext.strokeRect(displayX1, displayY1, width, height)
      
      // é‡ç½®ç»˜åˆ¶çŠ¶æ€
      canvasContext.setLineDash([])
      canvasContext.globalAlpha = 1.0
      
      // ç¨³å®šç›®æ ‡æ·»åŠ è§’æ ‡æç¤º
      if (result.isStable || result.is_stable) {
        canvasContext.fillStyle = color
        canvasContext.fillRect(displayX1 - 2, displayY1 - 2, 8, 8)
      }

      // ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
      let label = `${result.label || getDetectionLabel(result)} ${(result.confidence * 100).toFixed(1)}%`
      
      // ä¸ºä¸åŒçŠ¶æ€çš„ç›®æ ‡æ·»åŠ çŠ¶æ€æ ‡è¯†
      if (result.is_kept) {
        label += ' [ä¿æŒ]'
      } else if (result.isStable || result.is_stable) {
        label += ' [ç¨³å®š]'
      }
      
      canvasContext.font = 'bold 14px Arial'
      const textMetrics = canvasContext.measureText(label)
      const textWidth = textMetrics.width
      const textHeight = 18
      
      // ç¡®ä¿æ ‡ç­¾ä¸ä¼šè¶…å‡ºç”»å¸ƒè¾¹ç•Œ
      const labelX = Math.max(0, Math.min(displayX1, canvasWidth - textWidth - 10))
      const labelY = Math.max(textHeight, displayY1)
      
      canvasContext.fillStyle = color
      canvasContext.fillRect(labelX, labelY - textHeight, textWidth + 8, textHeight)

      // ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
      canvasContext.fillStyle = 'white'
      canvasContext.fillText(label, labelX + 4, labelY - 4)
    }
  })
  
  // ç»˜åˆ¶å®Œæˆ
}

// æµ‹è¯•æ£€æµ‹æ¡†æ˜¾ç¤º
const testDetectionBoxes = () => {
  if (!isStreaming.value) {
    ElMessage.warning('è¯·å…ˆå¯åŠ¨æ‘„åƒå¤´')
    return
  }
  
  // è·å–å½“å‰è§†é¢‘å°ºå¯¸ï¼Œç”Ÿæˆç›¸å¯¹åº”çš„æµ‹è¯•åæ ‡
  const video = videoElement.value
  if (!video) return
  
  const videoWidth = video.videoWidth || 640
  const videoHeight = video.videoHeight || 480
  
  // æµ‹è¯•åæ ‡åŸºäºå½“å‰ç¼©æ”¾æ¯”ä¾‹çš„å›¾åƒå°ºå¯¸
  const scaledWidth = videoWidth * currentImageScale
  const scaledHeight = videoHeight * currentImageScale
  
  const testResults = [
    {
      type: 'person',
      label: 'æµ‹è¯•äººå‘˜',
      confidence: 0.95,
      bbox: [
        scaledWidth * 0.1,   // å·¦ä¸ŠX (10%)
        scaledHeight * 0.1,  // å·¦ä¸ŠY (10%)
        scaledWidth * 0.4,   // å³ä¸‹X (40%)
        scaledHeight * 0.7   // å³ä¸‹Y (70%)
      ],
      timestamp: new Date()
    },
    {
      type: 'face', 
      label: 'æµ‹è¯•äººè„¸',
      confidence: 0.87,
      bbox: [
        scaledWidth * 0.15,  // å·¦ä¸ŠX (15%)
        scaledHeight * 0.15, // å·¦ä¸ŠY (15%)
        scaledWidth * 0.35,  // å³ä¸‹X (35%)
        scaledHeight * 0.4   // å³ä¸‹Y (40%)
      ],
      timestamp: new Date()
    },
    {
      type: 'unknown_face',
      label: 'æœªçŸ¥äººè„¸',
      confidence: 0.76,
      bbox: [
        scaledWidth * 0.6,   // å·¦ä¸ŠX (60%)
        scaledHeight * 0.2,  // å·¦ä¸ŠY (20%)
        scaledWidth * 0.8,   // å³ä¸‹X (80%)
        scaledHeight * 0.5   // å³ä¸‹Y (50%)
      ],
      timestamp: new Date()
    }
  ]
  
  console.log('æµ‹è¯•æ£€æµ‹æ¡†å‚æ•°:', {
    videoSize: [videoWidth, videoHeight],
    scaledSize: [scaledWidth, scaledHeight],
    currentImageScale,
    testResults
  })
  
  drawDetectionResults(testResults)
  updateDetectionResults(testResults)
  
  ElMessage.success('æµ‹è¯•æ£€æµ‹æ¡†å·²æ˜¾ç¤º')
}

// æ¸…é™¤æ£€æµ‹æ¡†
const clearDetectionBoxes = () => {
  if (!canvasContext || !overlayCanvas.value) return
  
  canvasContext.clearRect(0, 0, overlayCanvas.value.width, overlayCanvas.value.height)
  detectionResults.value = []
  lastFrameDetections.value = [] // æ¸…é™¤ç¼“å­˜
  console.log('âœ… å·²æ¸…é™¤æ‰€æœ‰æ£€æµ‹æ¡†å’Œç¼“å­˜')
  ElMessage.info('æ£€æµ‹æ¡†å·²æ¸…é™¤')
}

// é‡ç½®AIæ£€æµ‹ç¼“å­˜
const resetDetectionCache = async () => {
  try {
    const response = await fetch(`http://localhost:8001/detection/cache/clear/${cameraId}`, {
      method: 'POST'
    })
    
    if (response.ok) {
      const result = await response.json()
      if (result.status === 'success') {
        // åŒæ—¶æ¸…é™¤å‰ç«¯ç¼“å­˜
        clearDetectionBoxes()
        console.log('ğŸ”„ å·²é‡ç½®AIæ£€æµ‹ç¼“å­˜')
        ElMessage.success('æ£€æµ‹è·Ÿè¸ªå·²é‡ç½®')
      } else {
        console.error('é‡ç½®ç¼“å­˜å¤±è´¥:', result.message)
        ElMessage.error('é‡ç½®å¤±è´¥: ' + result.message)
      }
    } else {
      throw new Error('ç½‘ç»œè¯·æ±‚å¤±è´¥')
    }
  } catch (error) {
    console.error('é‡ç½®æ£€æµ‹ç¼“å­˜å¤±è´¥:', error)
    ElMessage.error('é‡ç½®ç¼“å­˜å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥')
  }
}

// è·å–æ£€æµ‹ç±»å‹å¯¹åº”çš„é¢œè‰²
const getDetectionColor = (type) => {
  const colors = {
    person: '#409EFF',
    face: '#67C23A',
    unknown_face: '#F56C6C',
    object: '#E6A23C'
  }
  return colors[type] || '#909399'
}

// è·å–æ£€æµ‹ç±»å‹å›¾æ ‡
const getDetectionIcon = (type) => {
  const icons = {
    person: 'ğŸ‘¤',
    face: 'ğŸ˜Š',
    unknown_face: 'â“',
    object: 'ğŸ“¦'
  }
  return icons[type] || 'ğŸ”'
}

// æ·»åŠ å‘Šè­¦ï¼ˆå¸¦å»é‡æœºåˆ¶ï¼‰
const addAlert = (alert) => {
  const now = Date.now()
  const alertKey = `${alert.type}_${alert.title}` // åŸºäºç±»å‹å’Œæ ‡é¢˜åˆ›å»ºå”¯ä¸€key
  
  // æ£€æŸ¥æ˜¯å¦åœ¨å†·å´æœŸå†…
  if (alertCooldowns.has(alertKey)) {
    const lastTime = alertCooldowns.get(alertKey)
    if (now - lastTime < ALERT_COOLDOWN) {
      return // åœ¨å†·å´æœŸå†…ï¼Œè·³è¿‡æ­¤æ¬¡å‘Šè­¦
    }
  }
  
  // æ›´æ–°å†·å´æ—¶é—´
  alertCooldowns.set(alertKey, now)
  
  // æ·»åŠ åˆ°å‘Šè­¦åˆ—è¡¨
  realtimeAlerts.value.unshift({
    ...alert,
    id: now
  })
  
  // é™åˆ¶å‘Šè­¦æ•°é‡
  if (realtimeAlerts.value.length > 10) {
    realtimeAlerts.value = realtimeAlerts.value.slice(0, 10)
  }
  
  // æ˜¾ç¤ºæ¡Œé¢é€šçŸ¥ï¼ˆä»…é‡è¦å‘Šè­¦ï¼‰
  if (alert.type === 'warning' || alert.type === 'error') {
    ElNotification({
      title: alert.title,
      message: alert.description,
      type: alert.type,
      duration: 4000,
      showClose: true
    })
  }
}

// ç§»é™¤å‘Šè­¦
const removeAlert = (index) => {
  realtimeAlerts.value.splice(index, 1)
}

// å‘é€éŸ³é¢‘å‘Šè­¦åˆ°AIæœåŠ¡
const sendAudioAlertToAI = async (audioLevel, eventType) => {
  try {
    const response = await fetch('http://localhost:8001/audio/frontend/alert/', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        camera_id: cameraId,
        audio_level: audioLevel,
        event_type: eventType,
        timestamp: new Date().toISOString()
      })
    })
    
    const result = await response.json()
    if (result.status !== 'success') {
      console.error('å‘é€éŸ³é¢‘å‘Šè­¦å¤±è´¥:', result.message)
    }
  } catch (error) {
    console.error('å‘é€éŸ³é¢‘å‘Šè­¦åˆ°AIæœåŠ¡å¤±è´¥:', error)
  }
}

// åˆ‡æ¢AIåˆ†æ
const toggleAIAnalysis = () => {
  if (aiAnalysisEnabled.value) {
    stopAIStream()
  } else {
    startAIStream()
  }
}

// æ›´æ–°AIè®¾ç½®
const updateAISettings = () => {
  if (aiAnalysisEnabled.value) {
    // é‡æ–°å¯åŠ¨AIåˆ†ææµä»¥åº”ç”¨æ–°è®¾ç½®
    stopAIStream().then(() => {
      setTimeout(() => {
        startAIStream()
      }, 1000)
    })
  }
}

// æ›´æ–°åˆ†æé—´éš”
const updateAnalysisInterval = () => {
  if (analysisTimer) {
    startFrameCapture() // é‡æ–°å¯åŠ¨å®šæ—¶å™¨
  }
}

// æ€§èƒ½ä¼˜åŒ–å»ºè®®
const getPerformanceAdvice = () => {
  const delay = performanceStats.avgProcessTime
  if (delay > 500) {
    return {
      level: 'error',
      title: 'å»¶è¿Ÿè¿‡é«˜',
      advice: 'å»ºè®®é™ä½æ£€æµ‹é¢‘ç‡æˆ–å…³é—­äººè„¸è¯†åˆ«åŠŸèƒ½'
    }
  } else if (delay > 300) {
    return {
      level: 'warning', 
      title: 'å»¶è¿Ÿè¾ƒé«˜',
      advice: 'ç³»ç»Ÿå·²è‡ªåŠ¨é™ä½ç”»è´¨å’Œåˆ†è¾¨ç‡'
    }
  } else if (delay > 150) {
    return {
      level: 'info',
      title: 'æ€§èƒ½è‰¯å¥½',
      advice: 'ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œå·²å¯ç”¨æ™ºèƒ½ä¼˜åŒ–'
    }
  } else {
    return {
      level: 'success',
      title: 'æ€§èƒ½ä¼˜ç§€',
      advice: 'ç³»ç»Ÿå“åº”è¿…é€Ÿï¼Œå¯é€‚å½“æé«˜æ£€æµ‹é¢‘ç‡'
    }
  }
}

// è§†é¢‘åŠ è½½å®Œæˆ
const onVideoLoaded = () => {
  nextTick(() => {
    if (overlayCanvas.value && videoElement.value) {
      // è·å–è§†é¢‘å…ƒç´ çš„å®é™…æ˜¾ç¤ºå°ºå¯¸
      const rect = videoElement.value.getBoundingClientRect()
      overlayCanvas.value.width = rect.width
      overlayCanvas.value.height = rect.height
      canvasContext = overlayCanvas.value.getContext('2d')
      
      // ç›‘å¬çª—å£å¤§å°å˜åŒ–ï¼ŒåŠ¨æ€è°ƒæ•´canvaså°ºå¯¸
      window.addEventListener('resize', resizeCanvas)
    }
  })
}

// è°ƒæ•´Canvaså°ºå¯¸ä»¥åŒ¹é…è§†é¢‘æ˜¾ç¤ºå°ºå¯¸
const resizeCanvas = () => {
  if (overlayCanvas.value && videoElement.value) {
    const rect = videoElement.value.getBoundingClientRect()
    overlayCanvas.value.width = rect.width
    overlayCanvas.value.height = rect.height
  }
}

// æ ¼å¼åŒ–æ—¶é—´
const formatTime = (date) => {
  return new Date(date).toLocaleTimeString()
}

// åŠ¨æ€è°ƒæ•´æ£€æµ‹é—´éš”ä»¥ä¼˜åŒ–æ€§èƒ½ï¼ˆå…¨å±€å‡½æ•°ï¼‰
const getDynamicInterval = () => {
  // å®æ—¶æ¨¡å¼ä¼˜å…ˆçº§æ›´é«˜
  if (aiSettings.realtimeMode) {
    if (performanceStats.avgProcessTime > 500) {
      return 150  // å®æ—¶æ¨¡å¼ä¸‹å³ä½¿é«˜å»¶è¿Ÿä¹Ÿä¿æŒè¾ƒé«˜é¢‘ç‡
    } else if (performanceStats.avgProcessTime > 300) {
      return 100  // å®æ—¶æ¨¡å¼ä¸­å»¶è¿Ÿ
    } else {
      return 66   // å®æ—¶æ¨¡å¼æ­£å¸¸æƒ…å†µï¼Œçº¦15fps
    }
  }
  
  // éå®æ—¶æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼Œä½†ç•¥å¾®ä¼˜åŒ–ï¼‰
  if (performanceStats.avgProcessTime > 400) {
    return 800   // é«˜å»¶è¿Ÿæ—¶é™ä½é¢‘ç‡ï¼ˆä»1000msä¼˜åŒ–åˆ°800msï¼‰
  } else if (performanceStats.avgProcessTime > 300) {
    return 600   // ä¸­é«˜å»¶è¿Ÿ
  } else if (performanceStats.avgProcessTime > 200) {
    return 400   // ä¸­å»¶è¿Ÿï¼ˆä»600msä¼˜åŒ–åˆ°400msï¼‰
  } else {
    return Math.max(analysisInterval.value, 200)  // æ­£å¸¸æƒ…å†µä½¿ç”¨ç”¨æˆ·è®¾ç½®æˆ–æœ€å°200ms
  }
}

// å®æ—¶æ¨¡å¼çŠ¶æ€ç›‘æ§
const logRealtimeStatus = () => {
  if (aiSettings.realtimeMode) {
    console.log(`ğŸš€ å®æ—¶æ¨¡å¼çŠ¶æ€:`, {
      interval: getDynamicInterval(),
      avgProcessTime: performanceStats.avgProcessTime,
      fps: performanceStats.fps,
      motionSkippedFrames: performanceStats.motionSkippedFrames,
      realtimeMode: aiSettings.realtimeMode
    })
  }
}

// ç›‘å¬å®æ—¶æ¨¡å¼å˜åŒ–
watch(() => aiSettings.realtimeMode, (newVal) => {
  console.log(`å®æ—¶æ¨¡å¼${newVal ? 'å¼€å¯' : 'å…³é—­'}`)
  if (newVal) {
    ElMessage.success('ğŸš€ å®æ—¶æ¨¡å¼å·²å¼€å¯ï¼Œæ£€æµ‹é¢‘ç‡æå‡è‡³~15FPS')
    setInterval(logRealtimeStatus, 3000) // æ¯3ç§’æ‰“å°ä¸€æ¬¡çŠ¶æ€
  } else {
    ElMessage.info('ğŸ’¡ å·²åˆ‡æ¢è‡³èŠ‚èƒ½æ¨¡å¼ï¼Œæ™ºèƒ½è°ƒé¢‘ä¼˜åŒ–')
  }
})

// ç”Ÿå‘½å‘¨æœŸ
onMounted(async () => {
  await getVideoDevices()
})

onUnmounted(() => {
  stopCamera()
  // ç§»é™¤çª—å£å¤§å°å˜åŒ–ç›‘å¬å™¨
  window.removeEventListener('resize', resizeCanvas)
})
</script>

<style scoped>
.ai-video-monitor {
  height: 100vh;
  background-color: #f5f7fa;
}

.header-content {
  height: 100%;
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 0 20px;
}

.header-content h2 {
  margin: 0;
  color: #2c3e50;
}

.video-card {
  height: calc(100vh - 140px);
}

.video-container {
  position: relative;
  width: 100%;
  height: 100%;
  background-color: #000;
  border-radius: 8px;
  overflow: hidden;
}

.video-player {
  width: 100%;
  height: 100%;
  object-fit: cover;
}

.overlay-canvas {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  pointer-events: none;
}

.camera-placeholder {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  text-align: center;
  color: #909399;
}

.placeholder-icon {
  font-size: 64px;
  margin-bottom: 20px;
}

.device-select {
  margin-top: 20px;
  width: 200px;
}

.control-panel,
.results-panel,
.performance-panel,
.alerts-panel {
  margin-bottom: 20px;
}

.card-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.analysis-settings {
  padding: 10px 0;
}

.frequency-hint {
  margin-top: 5px;
  text-align: center;
}

.frequency-hint small {
  color: #909399;
  font-size: 11px;
}

.performance-stats {
  display: flex;
  justify-content: space-between;
  gap: 15px;
}

.stat-item {
  text-align: center;
  flex: 1;
}

.stat-label {
  display: block;
  font-size: 12px;
  color: #909399;
  margin-bottom: 5px;
}

.stat-value {
  display: block;
  font-size: 18px;
  font-weight: 600;
  color: #409EFF;
}

.detection-list,
.alerts-list {
  max-height: 300px;
}

.detection-item {
  display: flex;
  align-items: center;
  padding: 12px;
  margin-bottom: 8px;
  border-radius: 6px;
  background-color: #f8f9fa;
  border-left: 4px solid #409EFF;
}

.detection-item.type-face {
  border-left-color: #67C23A;
}

.detection-item.type-unknown_face {
  border-left-color: #F56C6C;
}

.detection-icon {
  font-size: 24px;
  margin-right: 12px;
}

.detection-info {
  flex: 1;
}

.detection-name {
  font-weight: 600;
  color: #2c3e50;
}

.detection-details {
  font-size: 12px;
  color: #606266;
  margin: 2px 0;
}

.detection-time {
  font-size: 11px;
  color: #909399;
}

.no-results,
.no-alerts {
  text-align: center;
  padding: 40px 20px;
  color: #909399;
}

.no-results .el-icon,
.no-alerts .el-icon {
  font-size: 48px;
  margin-bottom: 10px;
}

.alert-item {
  margin-bottom: 10px;
}

.badge {
  margin-left: 10px;
}

/* æ€§èƒ½ä¼˜åŒ–çŠ¶æ€æ˜¾ç¤º */
.optimization-status {
  display: flex;
  flex-direction: column;
  gap: 8px;
}

.opt-item {
  display: flex;
  align-items: center;
  gap: 8px;
  font-size: 13px;
  color: #67c23a;
}

.opt-item .el-icon {
  color: #67c23a;
}

/* éŸ³é¢‘ç›‘æ§æ˜¾ç¤º */
.audio-monitor {
  width: 100%;
}

.audio-level-display {
  display: flex;
  flex-direction: column;
  gap: 8px;
}

.audio-text {
  font-size: 13px;
  color: #606266;
}

.audio-bar {
  width: 100%;
  height: 8px;
  background-color: #e4e7ed;
  border-radius: 4px;
  overflow: hidden;
}

.audio-level {
  height: 100%;
  border-radius: 4px;
  transition: all 0.3s ease;
  min-width: 2px;
}

/* æ€§èƒ½ç›‘æ§é¢æ¿å¢å¼º */
.performance-stats {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(80px, 1fr));
  gap: 15px;
}

.stat-item {
  background-color: #f8f9fa;
  padding: 10px 8px;
  border-radius: 6px;
  text-align: center;
  border: 1px solid #e4e7ed;
}

.stat-item:hover {
  border-color: #409eff;
  box-shadow: 0 2px 8px rgba(64, 158, 255, 0.1);
}

/* æ€§èƒ½å»ºè®®æ ·å¼ */
.performance-advice {
  margin-top: 10px;
}

.performance-advice .el-alert {
  border-radius: 6px;
}

/* ä¼˜åŒ–çŠ¶æ€åŠ¨ç”» */
.opt-item {
  transition: all 0.3s ease;
}

.opt-item:hover {
  transform: translateX(2px);
}

/* å»¶è¿ŸçŠ¶æ€é¢œè‰²æŒ‡ç¤º */
.el-text {
  font-weight: 500;
}

/* æµ‹è¯•æ§åˆ¶é¢æ¿ */
.test-controls {
  display: flex;
  flex-direction: column;
  gap: 8px;
  align-items: flex-start;
}

.test-controls .el-button {
  width: 100%;
}

.test-controls .el-text {
  font-size: 11px;
  color: #909399;
}
</style> 