# æ–‡ä»¶: ai_service/core/face_recognition.py
# æè¿°: æ™ºèƒ½äººè„¸è¯†åˆ«å™¨ï¼Œç”¨äºæ£€æµ‹ã€ç¼–ç å’Œè¯†åˆ«äººè„¸ï¼Œæ”¯æŒåŠ¨æ€çµæ•åº¦é…ç½®å’Œæ–°é¢å­”æ³¨å†Œã€‚

import face_recognition
import numpy as np
import os
import cv2
from typing import List, Dict, Any, Optional, Tuple
import logging
from datetime import datetime
import asyncio
# from concurrent.futures import ThreadPoolExecutor  # ã€ç§»é™¤ã€‘ä¸å†éœ€è¦çº¿ç¨‹æ± 

# è·å–loggerå®ä¾‹
logger = logging.getLogger(__name__)

# ã€ç§»é™¤ã€‘ä¸å†éœ€è¦å…¨å±€çº¿ç¨‹æ± 
# _face_loading_thread_pool = ThreadPoolExecutor(max_workers=os.cpu_count() or 4)


class FaceRecognizer:
    def __init__(self, known_faces_dir: str):
        """
        åˆå§‹åŒ–äººè„¸è¯†åˆ«å™¨ã€‚

        Args:
            known_faces_dir (str): åŒ…å«å·²çŸ¥äººè„¸å›¾ç‰‡çš„ç›®å½•è·¯å¾„ã€‚
                                ç›®å½•ç»“æ„åº”ä¸ºï¼šknown_faces_dir/person_name/image_files
        """
        self.known_faces = {}  # å­˜å‚¨æ¯ä¸ªäººçš„äººè„¸ç¼–ç  {name: [encodings]}
        self.enabled = True  # æ§åˆ¶æ£€æµ‹å™¨æ˜¯å¦å¯ç”¨

        # å†…éƒ¨é»˜è®¤æ£€æµ‹å‚æ•° (å¯è¢«å¤–éƒ¨é…ç½®è¦†ç›–)
        self._default_config = {
            'tolerance': 0.65,  # é»˜è®¤äººè„¸æ¯”å¯¹å®¹å¿åº¦
            'detection_model': 'auto',  # é»˜è®¤äººè„¸æ£€æµ‹æ¨¡å‹: 'hog', 'cnn', 'auto'
            'number_of_times_to_upsample': 2,  # æ£€æµ‹å‰å¯¹å›¾åƒè¿›è¡Œä¸Šé‡‡æ ·æ¬¡æ•°
            'min_face_size': 40,  # æœ€å°äººè„¸å°ºå¯¸ (åƒç´ )ï¼Œå°äºæ­¤å°ºå¯¸çš„äººè„¸å°†è¢«å¿½ç•¥
        }
        self.current_config = self._default_config.copy()  # å½“å‰ç”Ÿæ•ˆçš„é…ç½®

        self.known_faces_dir = known_faces_dir
        self.known_face_encodings = []
        self.known_face_names = []
        self.tolerance = self.current_config['tolerance']
        self.jitter = 1 # é»˜è®¤jitterå€¼

        self._load_known_faces()

    def _load_known_faces(self):
        """
        ä»æŒ‡å®šç›®å½•åŠ è½½å·²çŸ¥äººè„¸å¹¶ç”Ÿæˆç¼–ç ã€‚
        """
        logger.info("=== å¼€å§‹åŠ è½½å·²çŸ¥äººè„¸æ•°æ®åº“ ===")
        logger.info(f"ç›®å½•è·¯å¾„: {self.known_faces_dir}")

        self.known_face_encodings = []
        self.known_face_names = []

        if not os.path.isdir(self.known_faces_dir):
            logger.warning(f"å·²çŸ¥äººè„¸ç›®å½• '{self.known_faces_dir}' ä¸å­˜åœ¨ï¼Œè·³è¿‡åŠ è½½ã€‚")
            return

        for person_name in os.listdir(self.known_faces_dir):
            person_dir = os.path.join(self.known_faces_dir, person_name)
            if not os.path.isdir(person_dir):
                continue
            
            image_files = [f for f in os.listdir(person_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            logger.info(f"ğŸ“ å¤„ç†äººå‘˜ç›®å½•: {person_name}ï¼Œæ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")

            for image_file in image_files:
                try:
                    image_path = os.path.join(person_dir, image_file)
                    image = face_recognition.load_image_file(image_path)
                    face_locations = face_recognition.face_locations(image, model=self.current_config['detection_model'])
                    
                    if face_locations:
                        face_encoding = face_recognition.face_encodings(image, known_face_locations=face_locations, num_jitters=self.jitter)[0]
                        self.known_face_encodings.append(face_encoding)
                        self.known_face_names.append(person_name)
                    else:
                        logger.warning(f"åœ¨å›¾ç‰‡ '{image_file}' ä¸­æœªæ‰¾åˆ°äººè„¸ï¼Œå·²è·³è¿‡ã€‚")
                except Exception as e:
                    logger.error(f"å¤„ç†å›¾ç‰‡ '{image_file}' æ—¶å‡ºé”™: {e}", exc_info=True)
        
        logger.info(f"âœ… äººè„¸æ•°æ®åº“åŠ è½½å®Œæˆã€‚å…±åŠ è½½ {len(self.known_face_encodings)} ä¸ªå·²çŸ¥äººè„¸ã€‚")

    async def reload_known_faces(self):
        """
        å¼‚æ­¥æ¥å£ï¼Œåœ¨åå°çº¿ç¨‹ä¸­å®‰å…¨åœ°é‡æ–°åŠ è½½äººè„¸æ•°æ®ã€‚
        """
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, self._load_known_faces)

    def update_config(self, new_config: Dict[str, Any]):
        """
        æ›´æ–°äººè„¸è¯†åˆ«å™¨çš„é…ç½®å‚æ•°ã€‚
        Args:
            new_config (Dict[str, Any]): åŒ…å«è¦æ›´æ–°çš„é…ç½®é¡¹çš„å­—å…¸ã€‚
        """
        for key, value in new_config.items():
            if key in self.current_config:
                self.current_config[key] = value
                logger.info(f"æ›´æ–°äººè„¸è¯†åˆ«é…ç½®: {key} = {value}")
            else:
                logger.warning(f"å°è¯•æ›´æ–°ä¸å­˜åœ¨çš„é…ç½®é¡¹: {key}")
        logger.info(f"äººè„¸è¯†åˆ«å™¨å½“å‰é…ç½®: {self.current_config}")

    def set_enabled(self, enabled: bool):
        """å¯ç”¨æˆ–ç¦ç”¨äººè„¸è¯†åˆ«å™¨"""
        self.enabled = enabled
        logger.info(f"äººè„¸è¯†åˆ«å™¨å·²{'å¯ç”¨' if enabled else 'ç¦ç”¨'}")

    def add_face(self, image: np.ndarray, person_name: str) -> bool:
        """
        åœ¨è¿è¡Œæ—¶æ·»åŠ æ–°çš„äººè„¸åˆ°å·²çŸ¥äººè„¸æ•°æ®åº“ã€‚
        Args:
            image (np.ndarray): åŒ…å«æ–°äººè„¸çš„å›¾åƒ (BGRæ ¼å¼)ã€‚
            person_name (str): æ–°äººè„¸çš„åç§°ã€‚
        Returns:
            bool: å¦‚æœæˆåŠŸæ·»åŠ äººè„¸è¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚
        """
        if not self.enabled:
            logger.warning("äººè„¸è¯†åˆ«å™¨å·²ç¦ç”¨ï¼Œæ— æ³•æ·»åŠ æ–°é¢å­”ã€‚")
            return False

        try:
            # è½¬æ¢ä¸ºRGBæ ¼å¼ï¼ˆface_recognitionåº“è¦æ±‚ï¼‰
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # ä½¿ç”¨å½“å‰é…ç½®æ£€æµ‹äººè„¸
            face_locations = face_recognition.face_locations(
                rgb_image,
                model=self.current_config['detection_model'] if self.current_config[
                                                                    'detection_model'] != 'auto' else 'hog',
                number_of_times_to_upsample=self.current_config['number_of_times_to_upsample']
            )

            if not face_locations:
                logger.warning(f"æœªåœ¨æä¾›çš„å›¾åƒä¸­æ£€æµ‹åˆ°äººè„¸ï¼Œæ— æ³•æ³¨å†Œ '{person_name}'ã€‚")
                return False

            # è¿‡æ»¤æ‰è¿‡å°çš„äººè„¸
            filtered_locations = [
                loc for loc in face_locations
                if (loc[2] - loc[0]) >= self.current_config['min_face_size'] and
                   (loc[1] - loc[3]) >= self.current_config['min_face_size']
            ]

            if not filtered_locations:
                logger.warning(
                    f"æ£€æµ‹åˆ°çš„äººè„¸å°ºå¯¸è¿‡å°ï¼Œæ— æ³•æ³¨å†Œ '{person_name}' (æœ€å°å°ºå¯¸è¦æ±‚: {self.current_config['min_face_size']}px)ã€‚")
                return False

            face_encodings = face_recognition.face_encodings(rgb_image, filtered_locations)

            if not face_encodings:
                logger.warning(f"æ— æ³•ä»å›¾åƒä¸­æå–äººè„¸ç‰¹å¾ï¼Œæ— æ³•æ³¨å†Œ '{person_name}'ã€‚")
                return False

            # å°†æ–°æå–çš„ç¼–ç æ·»åŠ åˆ°å†…å­˜ä¸­çš„å·²çŸ¥äººè„¸å­—å…¸
            if person_name not in self.known_faces:
                self.known_faces[person_name] = []
            self.known_faces[person_name].extend(face_encodings)

            # å¯é€‰ï¼šå°†æ–°æ³¨å†Œçš„äººè„¸å›¾ç‰‡ä¿å­˜åˆ° known_faces_dir å¯¹åº”çš„å­ç›®å½•
            person_dir = os.path.join(self.known_faces_dir, person_name)
            os.makedirs(person_dir, exist_ok=True)
            # ä¿å­˜ä¸€ä¸ªå‰¯æœ¬ï¼Œç”¨äºæŒä¹…åŒ–
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_image_path = os.path.join(person_dir, f"{person_name}_{timestamp}.jpg")
            cv2.imwrite(output_image_path, image)

            logger.info(f"æˆåŠŸæ³¨å†Œäººè„¸ '{person_name}'ï¼Œæå– {len(face_encodings)} ä¸ªç‰¹å¾ï¼Œä¿å­˜åˆ° {output_image_path}")
            return True

        except Exception as e:
            logger.error(f"æ³¨å†Œäººè„¸ '{person_name}' æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
            return False

    def detect_and_recognize(self, frame: np.ndarray) -> List[Dict]:
        """
        åœ¨å•å¸§å›¾åƒä¸­æ£€æµ‹å¹¶è¯†åˆ«äººè„¸ã€‚
        Args:
            frame (np.ndarray): BGRæ ¼å¼çš„è§†é¢‘å¸§ã€‚
        Returns:
            List[Dict]: ä¸€ä¸ªåŒ…å«æ£€æµ‹åˆ°çš„æ‰€æœ‰äººè„¸ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨ã€‚
        """
        if not self.enabled:
            return []

        results = []

        # è·å–å½“å‰é…ç½®
        tolerance = self.current_config['tolerance']
        detection_model = self.current_config['detection_model']
        upsample_times = self.current_config['number_of_times_to_upsample']
        min_face_size = self.current_config['min_face_size']

        # è½¬æ¢ä¸ºRGBæ ¼å¼ï¼ˆface_recognitionåº“è¦æ±‚ï¼‰
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        face_locations = []

        # ğŸ¯ ä¼˜åŒ–äººè„¸æ£€æµ‹ï¼šæ ¹æ®é…ç½®é€‰æ‹©æ¨¡å‹å’Œå‚æ•°
        try:
            if detection_model == "cnn":
                face_locations = face_recognition.face_locations(rgb_frame, model="cnn",
                                                                 number_of_times_to_upsample=upsample_times)
            elif detection_model == "hog":
                face_locations = face_recognition.face_locations(rgb_frame, model="hog",
                                                                 number_of_times_to_upsample=upsample_times)
            else:  # auto æˆ–å…¶ä»–æœªæŒ‡å®šæ¨¡å‹æ—¶ï¼Œå°è¯•å¤šæ¨¡å‹ç­–ç•¥
                # ä¼˜å…ˆä½¿ç”¨hogï¼Œå› ä¸ºå®ƒé€šå¸¸æ›´å¿«
                face_locations = face_recognition.face_locations(rgb_frame, model="hog",
                                                                 number_of_times_to_upsample=upsample_times)
                if not face_locations and upsample_times < 3:  # å¦‚æœhogæ²¡æ£€æµ‹åˆ°ä¸”ä¸Šé‡‡æ ·æ¬¡æ•°ä¸é«˜ï¼Œå°è¯•æ›´é«˜çš„ä¸Šé‡‡æ ·
                    face_locations = face_recognition.face_locations(rgb_frame, model="hog",
                                                                     number_of_times_to_upsample=upsample_times + 1)
                if not face_locations:  # å¦‚æœhogä»æ²¡æ£€æµ‹åˆ°ï¼Œå°è¯•cnn
                    face_locations = face_recognition.face_locations(rgb_frame, model="cnn",
                                                                     number_of_times_to_upsample=upsample_times)

            if face_locations:
                logger.debug(f"ğŸ¯ æ£€æµ‹æ¨¡å‹ '{detection_model}' æ£€æµ‹åˆ° {len(face_locations)} ä¸ªäººè„¸")
        except Exception as e:
            logger.error(f"äººè„¸æ£€æµ‹å¤±è´¥: {str(e)}", exc_info=True)
            return []  # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œç›´æ¥è¿”å›ç©ºåˆ—è¡¨

        # è¿‡æ»¤æ‰è¿‡å°çš„äººè„¸
        filtered_face_locations = []
        for (top, right, bottom, left) in face_locations:
            face_height = bottom - top
            face_width = right - left
            if face_height >= min_face_size and face_width >= min_face_size:
                filtered_face_locations.append((top, right, bottom, left))
            else:
                logger.debug(f"  è¿‡æ»¤æ‰è¿‡å°äººè„¸: H={face_height}, W={face_width} (Min size: {min_face_size}px)")

        if not filtered_face_locations:
            logger.debug("âš ï¸ æœªæ£€æµ‹åˆ°æ»¡è¶³å°ºå¯¸è¦æ±‚çš„äººè„¸")
            return results

        # æå–äººè„¸ç‰¹å¾
        face_encodings = face_recognition.face_encodings(rgb_frame, filtered_face_locations)

        # å¯¹æ¯ä¸ªæ£€æµ‹åˆ°çš„äººè„¸è¿›è¡Œè¯†åˆ«
        for face_idx, (face_location, face_encoding) in enumerate(zip(filtered_face_locations, face_encodings)):
            top, right, bottom, left = face_location

            # ä¸æ‰€æœ‰å·²çŸ¥äººè„¸è¿›è¡Œæ¯”å¯¹
            all_distances = {}  # {name: [distances]}
            for known_name, known_encodings in self.known_faces.items():
                if known_encodings:  # ç¡®ä¿æœ‰å·²çŸ¥ç¼–ç 
                    # è®¡ç®—äººè„¸ç‰¹å¾å‘é‡çš„æ¬§æ°è·ç¦»
                    # ã€ä¿®å¤ 3.1ã€‘å°† face_recognition.face_distances æ›´æ­£ä¸º face_recognition.face_distance
                    distances = face_recognition.face_distance(known_encodings, face_encoding)
                    all_distances[known_name] = distances.tolist()  # è½¬æ¢ä¸ºåˆ—è¡¨

            best_matches = []
            for name, distances in all_distances.items():
                if distances:
                    min_distance = min(distances)
                    avg_distance = sum(distances) / len(distances)
                    best_matches.append((name, min_distance, avg_distance))

            best_matches.sort(key=lambda x: x[1])  # æŒ‰æœ€å°è·ç¦»æ’åº

            identity = {"name": "unknown", "known": False, "confidence": 0.0}
            confidence_score = 0.0

            if best_matches:
                best_name, best_distance, avg_distance = best_matches[0]

                # ğŸ¯ ä¼˜åŒ–åçš„è¯†åˆ«åˆ¤æ–­ï¼šæ›´çµæ•ä½†ä»å‡†ç¡®
                # 1. åŸºç¡€é˜ˆå€¼æ£€æŸ¥ï¼šæœ€ä½³åŒ¹é…å¿…é¡»å°äºåŸºç¡€é˜ˆå€¼
                passes_base_threshold = best_distance <= tolerance

                # 2. ç®€åŒ–çš„å·®å¼‚åº¦æ£€æŸ¥ï¼šå¦‚æœæœ‰å…¶ä»–å€™é€‰äººï¼Œç¡®ä¿æœ‰ä¸€å®šå·®è·
                # é¿å…è¢«ç¬¬äºŒç›¸ä¼¼çš„äººè„¸å¹²æ‰°
                passes_distinction = True
                if len(best_matches) > 1:
                    second_best_distance = best_matches[1][1]
                    # ç¡®ä¿æœ€ä½³åŒ¹é…ä¸æ¬¡ä½³åŒ¹é…ä¹‹é—´æœ‰è¶³å¤Ÿçš„è·ç¦»å·®å¼‚
                    if best_distance > 0:  # é¿å…é™¤ä»¥é›¶
                        distance_gap_ratio = (second_best_distance - best_distance) / best_distance
                        if distance_gap_ratio < 0.12:  # é™ä½å·®è·è¦æ±‚ä»15%åˆ°12%
                            passes_distinction = False

                # 3. é€‚ä¸­çš„ç»å¯¹é˜ˆå€¼æ£€æŸ¥ï¼šè¿›ä¸€æ­¥æ”¾å®½ç¡¬æ€§ä¸Šé™
                passes_absolute = best_distance <= 0.75  # æ”¾å®½ä»0.65åˆ°0.75

                # ğŸ”¥ æ‰©å±•ï¼šé«˜ç½®ä¿¡åº¦å¿«é€Ÿé€šé“ - æ‰©å¤§å¿«é€Ÿé€šé“èŒƒå›´
                is_high_confidence = best_distance <= 0.45  # ä»0.35æ‰©å±•åˆ°0.45

                # ğŸŒŸ æ–°å¢ï¼šä¸­ç­‰ç½®ä¿¡åº¦é€šé“ - åœ¨é«˜ç½®ä¿¡åº¦å’Œæ ‡å‡†æ£€æŸ¥ä¹‹é—´å¢åŠ ä¸­é—´å±‚
                is_medium_confidence = (best_distance <= 0.55 and passes_base_threshold)

                # ç»¼åˆåˆ¤æ–­ï¼šå¤šçº§é€šé“æé«˜è¯†åˆ«ç‡
                is_confident = (
                        is_high_confidence or  # é«˜ç½®ä¿¡åº¦å¿«é€Ÿé€šé“
                        is_medium_confidence or  # ä¸­ç­‰ç½®ä¿¡åº¦é€šé“
                        (passes_base_threshold and passes_distinction and passes_absolute)
                )

                if is_confident:
                    confidence_score = max(0.0, 1.0 - best_distance)  # è·ç¦»è¶Šå°ï¼Œç½®ä¿¡åº¦è¶Šé«˜
                    identity = {"name": best_name, "known": True, "confidence": confidence_score}
                    logger.debug(f"  âœ… è¯†åˆ«ä¸º: {best_name} (è·ç¦»: {best_distance:.3f}, ç½®ä¿¡åº¦: {confidence_score:.3f})")
                    if is_high_confidence:
                        logger.debug(f"    ğŸš€ é«˜ç½®ä¿¡åº¦å¿«é€Ÿé€šé“: {best_distance:.3f} <= 0.45")
                    elif is_medium_confidence:
                        logger.debug(f"    ğŸ¯ ä¸­ç­‰ç½®ä¿¡åº¦é€šé“: {best_distance:.3f} <= 0.55")
                    else:
                        logger.debug(
                            f"    ğŸ“Š æ ‡å‡†æ£€æŸ¥é€šè¿‡: åŸºç¡€é˜ˆå€¼={passes_base_threshold}, å·®å¼‚={passes_distinction}, ç»å¯¹={passes_absolute}")
                else:
                    identity = {"name": "unknown", "known": False, "confidence": 0.0}
                    logger.debug(f"  âŒ æœªçŸ¥äººå‘˜ (æœ€ä½³è·ç¦»: {best_distance:.3f})")
                    logger.debug(
                        f"    ğŸ” æ£€æŸ¥æœªé€šè¿‡: é«˜ç½®ä¿¡åº¦={is_high_confidence}, ä¸­ç­‰ç½®ä¿¡åº¦={is_medium_confidence}, åŸºç¡€é˜ˆå€¼={passes_base_threshold}, å·®å¼‚={passes_distinction}, ç»å¯¹={passes_absolute}")
            else:
                logger.debug("  æ²¡æœ‰å·²çŸ¥äººè„¸åŒ¹é…ã€‚")

            results.append({
                "location": {"top": top, "right": right, "bottom": bottom, "left": left},
                "identity": identity,
                "confidence": confidence_score,
                "alert_needed": identity["name"] == "unknown",
                "best_match": best_matches[0] if best_matches else None,
                "detection_time": datetime.now().isoformat()
            })

        return results